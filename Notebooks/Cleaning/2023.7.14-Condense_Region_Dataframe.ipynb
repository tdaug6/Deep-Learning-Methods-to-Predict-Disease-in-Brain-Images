{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343ab3b6",
   "metadata": {},
   "source": [
    "# Condense Region Dataframe\n",
    "\n",
    "This notebook attempts to extract the most important features from the average region intensity. \n",
    "The original dataset is the average region intensity for the subjects from all the sites.\n",
    "The output dataset will be the regions from the original dataset that have the highest correlation to the diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654a84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fc6b7",
   "metadata": {},
   "source": [
    "### get_base_filepath()\n",
    "\n",
    "Access the filepath for th ebase folder of the project. \n",
    "From here, any other asset of the project can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ee7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filepath():\n",
    "    '''\n",
    "    Access the filepath for the base folder of the project\n",
    "    \n",
    "    Input: None\n",
    "    \n",
    "    Output: The filepath to the root of the folder\n",
    "    '''\n",
    "    # Get current directory\n",
    "    os.path.abspath(os.curdir)\n",
    "\n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "    os.chdir('..')\n",
    "\n",
    "    # Set baseline filepath to the project folder directory\n",
    "    base_folder_filepath = os.path.abspath(os.curdir)\n",
    "    return base_folder_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdb6d7",
   "metadata": {},
   "source": [
    "### extract_features()\n",
    "\n",
    "Create a dataframe using the mean of regions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ab70fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filepath):\n",
    "    '''\n",
    "    Create a dataframe using the mean of regions over time.\n",
    "    \n",
    "    Input: filepath to open the dataframe\n",
    "    \n",
    "    Output: dataframe of mean for each region\n",
    "    '''\n",
    "    # Read the filepath as a dataframe (use 1 tab as separator and the first line as the header)\n",
    "    df = pd.read_csv(filepath, sep=r'\\s{1,}', engine='python', header=0)\n",
    "    \n",
    "    # Drop two features that get in the way of evaluation\n",
    "    df = df.drop('File', axis=1)\n",
    "    df = df.drop('Sub-brick', axis=1)\n",
    "    \n",
    "    # Return the mean for each of the features (method of vectorizing)\n",
    "    return df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da4d41",
   "metadata": {},
   "source": [
    "## Open files\n",
    "\n",
    "In this section, the files for all of the patients is opened and combined into two matrices to build a dataframe in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d44b97",
   "metadata": {},
   "source": [
    "###  Filepaths\n",
    "\n",
    "Access the filepath to the preprocessed data folder. \n",
    "This is where the data for all of the sites are located.\n",
    "\n",
    "The filepath to the phenotypic data folder is also added here. \n",
    "This is where all of the phenotypic data files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c898006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder for the project\n",
    "base_folder_filepath = get_base_filepath()\n",
    "\n",
    "# Preprocessed data site folder\n",
    "sites_filepath = base_folder_filepath +  '\\\\Data\\\\Preprocessed_data\\\\Sites\\\\'\n",
    "\n",
    "# Phenotypic data site folder\n",
    "phenotypics_filepath = base_folder_filepath + '\\\\Data\\\\Phenotypic\\\\Sites\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc9f06",
   "metadata": {},
   "source": [
    "### Subjects\n",
    "\n",
    "Open the 'sfnwmrda' file for each subject in the study. \n",
    "\n",
    "Add the features to a matrix and the subjects to a different matrix.\n",
    "\n",
    "There may be instances where the subject does not have the file in their folder. \n",
    "In this case, add the subject to a matrix to be dropped from the phenotypic dataframe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017bf29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty folder: 0010016\n",
      "Skipping empty folder: 0010027\n",
      "Skipping empty folder: 0010055\n",
      "Skipping empty folder: 0010098\n",
      "Skipping empty folder: 0010105\n",
      "Skipping empty folder: 0010127\n",
      "Skipping folder sfnwmrda0015001_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015004_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping empty folder: 0015011\n",
      "Skipping folder sfnwmrda0015016_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping empty folder: 0015018\n",
      "Skipping folder sfnwmrda0015026_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015027_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015032_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015036_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015052_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015057_session_1_rest_1_aal_TCs.1D: not found.\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store important values\n",
    "subjects = []\n",
    "subject_features = []\n",
    "subjects_dropped = []\n",
    "\n",
    "# Loop through every site in the folder\n",
    "for site_folder in os.listdir(sites_filepath):\n",
    "    # Access the filepath to the site's folder\n",
    "    site_folder_path = os.path.join(sites_filepath, site_folder)\n",
    "        \n",
    "    # Loop through every patient in the site's folder\n",
    "    for patient_id_folder in os.listdir(site_folder_path):            \n",
    "        # Access the filepath to the patient's folder\n",
    "        patient_id_folder_path = os.path.join(site_folder_path, patient_id_folder)\n",
    "        \n",
    "        # Skip the folder if it is empty\n",
    "        if len(os.listdir(patient_id_folder_path)) == 0:\n",
    "            print(f\"Skipping empty folder: {patient_id_folder}\")\n",
    "            subjects_dropped.append(patient_id_folder)\n",
    "            continue\n",
    "\n",
    "        # Check if the filepath is a folder, continue if it is\n",
    "        if os.path.isdir(patient_id_folder_path):\n",
    "            # Get the file name (dependent on folder name)\n",
    "            file_name = f\"sfnwmrda{patient_id_folder}_session_1_rest_1_aal_TCs.1D\"\n",
    "            \n",
    "            # Join the file name to its path\n",
    "            file_path = os.path.join(patient_id_folder_path, file_name)\n",
    "            \n",
    "            # Skip the folder if the file is not in it\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Skipping folder {file_name}: not found.\")\n",
    "                subjects_dropped.append(patient_id_folder)\n",
    "                continue\n",
    "\n",
    "            # Extract the features and add it to the list of subjects\n",
    "            subject_features.append(extract_features(file_path))\n",
    "            \n",
    "            # Add the patient ID to the subjects list\n",
    "            subjects.append(patient_id_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a450316",
   "metadata": {},
   "source": [
    "### Diagnosis\n",
    "\n",
    "Open the phenotypic file for each subject in the study. \n",
    "\n",
    "Add the diagnosis to a matrix and the patient id to a different matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5a2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store important values\n",
    "dx = [] # For the diagnosis\n",
    "pheno_index = [] # For the patient id\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for site_pheno in os.listdir(phenotypics_filepath):\n",
    "    # Access the filepath to the phenotypic data\n",
    "    site_pheno_filepath = os.path.join(phenotypics_filepath, site_pheno)\n",
    "    \n",
    "    # Check if the current item in the directory is a file\n",
    "    if os.path.isfile(site_pheno_filepath):\n",
    "        # Read the file as a dataframe\n",
    "        df_pheno = pd.read_csv(site_pheno_filepath, index_col='ScanDir ID')\n",
    "        \n",
    "        # Add the diagnosis to the list\n",
    "        dx.append(df_pheno['DX'])\n",
    "        \n",
    "        # Add the patient id to the list\n",
    "        pheno_index.append(df_pheno.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eddd5d",
   "metadata": {},
   "source": [
    "## Build the dataframe\n",
    "\n",
    "Create a dataframe of the subjects, regions and their diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e87dd",
   "metadata": {},
   "source": [
    "### Subject x Region\n",
    "\n",
    "Build a matrix of subjects vs. regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7d35d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_2001</th>\n",
       "      <th>Mean_2002</th>\n",
       "      <th>Mean_2101</th>\n",
       "      <th>Mean_2102</th>\n",
       "      <th>Mean_2111</th>\n",
       "      <th>Mean_2112</th>\n",
       "      <th>Mean_2201</th>\n",
       "      <th>Mean_2202</th>\n",
       "      <th>Mean_2211</th>\n",
       "      <th>Mean_2212</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_9081</th>\n",
       "      <th>Mean_9082</th>\n",
       "      <th>Mean_9100</th>\n",
       "      <th>Mean_9110</th>\n",
       "      <th>Mean_9120</th>\n",
       "      <th>Mean_9130</th>\n",
       "      <th>Mean_9140</th>\n",
       "      <th>Mean_9150</th>\n",
       "      <th>Mean_9160</th>\n",
       "      <th>Mean_9170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010001</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010002</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.004370</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010003</th>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>-0.007068</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>-0.011144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010004</th>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.003498</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.004143</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.005601</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010005</th>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.007235</td>\n",
       "      <td>-0.008659</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.001598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean_2001  Mean_2002  Mean_2101  Mean_2102  Mean_2111  Mean_2112   \n",
       "0010001   0.001918   0.001396   0.000917   0.001579   0.001620   0.000398  \\\n",
       "0010002   0.000535  -0.000911  -0.004370   0.000013  -0.012312   0.001798   \n",
       "0010003   0.004598   0.001763   0.001807  -0.000461  -0.004121  -0.007068   \n",
       "0010004  -0.000559   0.000830  -0.003498  -0.001282  -0.004143   0.001574   \n",
       "0010005   0.003364   0.006273   0.014627   0.015924   0.000704   0.002034   \n",
       "\n",
       "         Mean_2201  Mean_2202  Mean_2211  Mean_2212  ...  Mean_9081   \n",
       "0010001   0.000401   0.000248  -0.000006  -0.001791  ...  -0.001946  \\\n",
       "0010002  -0.001885   0.000525  -0.002277   0.015622  ...  -0.000176   \n",
       "0010003   0.003899   0.004255  -0.001597  -0.011144  ...  -0.001121   \n",
       "0010004  -0.001477  -0.000162  -0.005601   0.002853  ...   0.000800   \n",
       "0010005   0.016690   0.014993   0.004241   0.008220  ...   0.007601   \n",
       "\n",
       "         Mean_9082  Mean_9100  Mean_9110  Mean_9120  Mean_9130  Mean_9140   \n",
       "0010001  -0.001540   0.002221   0.001640  -0.000227  -0.000473  -0.000525  \\\n",
       "0010002  -0.001465  -0.002169  -0.000968   0.001107   0.001050   0.000374   \n",
       "0010003  -0.001566  -0.009230  -0.002198   0.006707   0.009246  -0.000108   \n",
       "0010004  -0.000904  -0.000326   0.000155   0.003007   0.001742   0.002644   \n",
       "0010005   0.004895   0.001707  -0.004593  -0.007235  -0.008659  -0.007546   \n",
       "\n",
       "         Mean_9150  Mean_9160  Mean_9170  \n",
       "0010001   0.002460   0.001810  -0.000823  \n",
       "0010002  -0.000629  -0.000025   0.001806  \n",
       "0010003   0.001620  -0.000059  -0.007794  \n",
       "0010004   0.000302  -0.000304  -0.000530  \n",
       "0010005  -0.000393  -0.003564  -0.001598  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Turn the array of features into a dataframe with the index as the subject id\n",
    "df_subject_x_region = pd.DataFrame(subject_features, index=subjects)\n",
    "df_subject_x_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a88ba",
   "metadata": {},
   "source": [
    "### Diagnosis Series\n",
    "\n",
    "Create a series of the patient diagnosis to combine with the region dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e89be6",
   "metadata": {},
   "source": [
    "Make a vector of the patient ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e88a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condense the indicies in the phenotypic data to a vector\n",
    "patient_ids = [p_id for site_pheno in pheno_index for p_id in site_pheno]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb70421",
   "metadata": {},
   "source": [
    "Unify patient id formatting and create a series for the diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac8f7ac2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fix some of the patient ids\n",
    "for i in range (len(patient_ids)):\n",
    "    # Access the current patient id\n",
    "    s_id = patient_ids[i]\n",
    "    \n",
    "    # If the length of the patient id is 5...\n",
    "    if len(str(s_id)) == 5:\n",
    "        # ... add '00' to the beginning to match formatting with the folder names\n",
    "        patient_ids[i] = '00' + str(s_id)\n",
    "        \n",
    "    # Otherwise, turn the current id into a string value\n",
    "    else:\n",
    "        patient_ids[i] = str(s_id)\n",
    "    \n",
    "# Make the diagnosis a series with the phenotypic array as the index\n",
    "diagnosis = pd.Series([diag for site_pheno in dx for diag in site_pheno], index=patient_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be3dfc",
   "metadata": {},
   "source": [
    "### Combine\n",
    "\n",
    "Add the diagnosis Series to the regions dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26439d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_2001</th>\n",
       "      <th>Mean_2002</th>\n",
       "      <th>Mean_2101</th>\n",
       "      <th>Mean_2102</th>\n",
       "      <th>Mean_2111</th>\n",
       "      <th>Mean_2112</th>\n",
       "      <th>Mean_2201</th>\n",
       "      <th>Mean_2202</th>\n",
       "      <th>Mean_2211</th>\n",
       "      <th>Mean_2212</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_9082</th>\n",
       "      <th>Mean_9100</th>\n",
       "      <th>Mean_9110</th>\n",
       "      <th>Mean_9120</th>\n",
       "      <th>Mean_9130</th>\n",
       "      <th>Mean_9140</th>\n",
       "      <th>Mean_9150</th>\n",
       "      <th>Mean_9160</th>\n",
       "      <th>Mean_9170</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010001</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010002</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.004370</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010003</th>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>-0.007068</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>-0.011144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010004</th>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.003498</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.004143</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.005601</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010005</th>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.007235</td>\n",
       "      <td>-0.008659</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean_2001  Mean_2002  Mean_2101  Mean_2102  Mean_2111  Mean_2112   \n",
       "0010001   0.001918   0.001396   0.000917   0.001579   0.001620   0.000398  \\\n",
       "0010002   0.000535  -0.000911  -0.004370   0.000013  -0.012312   0.001798   \n",
       "0010003   0.004598   0.001763   0.001807  -0.000461  -0.004121  -0.007068   \n",
       "0010004  -0.000559   0.000830  -0.003498  -0.001282  -0.004143   0.001574   \n",
       "0010005   0.003364   0.006273   0.014627   0.015924   0.000704   0.002034   \n",
       "\n",
       "         Mean_2201  Mean_2202  Mean_2211  Mean_2212  ...  Mean_9082   \n",
       "0010001   0.000401   0.000248  -0.000006  -0.001791  ...  -0.001540  \\\n",
       "0010002  -0.001885   0.000525  -0.002277   0.015622  ...  -0.001465   \n",
       "0010003   0.003899   0.004255  -0.001597  -0.011144  ...  -0.001566   \n",
       "0010004  -0.001477  -0.000162  -0.005601   0.002853  ...  -0.000904   \n",
       "0010005   0.016690   0.014993   0.004241   0.008220  ...   0.004895   \n",
       "\n",
       "         Mean_9100  Mean_9110  Mean_9120  Mean_9130  Mean_9140  Mean_9150   \n",
       "0010001   0.002221   0.001640  -0.000227  -0.000473  -0.000525   0.002460  \\\n",
       "0010002  -0.002169  -0.000968   0.001107   0.001050   0.000374  -0.000629   \n",
       "0010003  -0.009230  -0.002198   0.006707   0.009246  -0.000108   0.001620   \n",
       "0010004  -0.000326   0.000155   0.003007   0.001742   0.002644   0.000302   \n",
       "0010005   0.001707  -0.004593  -0.007235  -0.008659  -0.007546  -0.000393   \n",
       "\n",
       "         Mean_9160  Mean_9170  DX  \n",
       "0010001   0.001810  -0.000823   3  \n",
       "0010002  -0.000025   0.001806   3  \n",
       "0010003  -0.000059  -0.007794   0  \n",
       "0010004  -0.000304  -0.000530   0  \n",
       "0010005  -0.003564  -0.001598   2  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the region dataframe\n",
    "df_region_w_dx = df_subject_x_region.copy()\n",
    "\n",
    "# Drop the rows with missing files or folders from the Series\n",
    "filtered_diagnosis = diagnosis.drop(index=subjects_dropped)\n",
    "\n",
    "# Add the diagnosis to the region dataframe\n",
    "df_region_w_dx['DX'] = filtered_diagnosis\n",
    "\n",
    "df_region_w_dx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155dc51",
   "metadata": {},
   "source": [
    "## Determine Features\n",
    "\n",
    "Determine what features are most correlated to the diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0eea4b",
   "metadata": {},
   "source": [
    "Find the correlations of each feature to the diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5081d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_region_w_dx.drop('DX', axis=1).corrwith(df_region_w_dx['DX'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabd697",
   "metadata": {},
   "source": [
    "Find all of the features that have the most significant correlation to the diagonsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d654d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_features = correlations.loc[abs(correlations) >= 0.05]\n",
    "correlation_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03976609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_region_w_dx.drop('DX', axis=1)\n",
    "y = df_region_w_dx['DX']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fab725",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_train = X_train.corrwith(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfbb5347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_features_train = correlations_train.loc[abs(correlations_train) >= 0.05]\n",
    "correlation_features_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b15e4",
   "metadata": {},
   "source": [
    "Create a dataframe of only the features with the highest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9f10bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Temp\\ipykernel_17880\\444374315.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_correlation_features['DX'] = df_region_w_dx['DX']\n",
      "C:\\Users\\taylo\\AppData\\Local\\Temp\\ipykernel_17880\\444374315.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_correlation_features_train['DX'] = df_region_w_dx['DX']\n"
     ]
    }
   ],
   "source": [
    "df_correlation_features = df_region_w_dx[correlation_features.index]\n",
    "df_correlation_features['DX'] = df_region_w_dx['DX']\n",
    "\n",
    "df_correlation_features_train = df_region_w_dx[correlation_features_train.index]\n",
    "df_correlation_features_train['DX'] = df_region_w_dx['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c809e",
   "metadata": {},
   "source": [
    "Export condensed dataframe as a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "428ba68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation_features.to_csv(base_folder_filepath + '\\\\Data\\\\Preprocessed_data\\\\Condensed\\\\2023.7.14-Region_Condensed_Dataframe.csv')\n",
    "df_correlation_features_train.to_csv(base_folder_filepath + '\\\\Data\\\\Preprocessed_data\\\\Condensed\\\\2023.7.20-Region_Condensed_Train_Dataframe.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
