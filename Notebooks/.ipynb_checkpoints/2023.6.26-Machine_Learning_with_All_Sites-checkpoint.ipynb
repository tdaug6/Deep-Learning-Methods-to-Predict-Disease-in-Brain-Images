{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc9a404",
   "metadata": {},
   "source": [
    "# Machine Learning with All Sites\n",
    "\n",
    "This notebook investigates the performance of machine learning models to recognize ADHD in subjects. \n",
    "This dataset consits of preprocessed data from 6 of the 7 sites from the ADHD-200 Competition set and the diagnosis corresponding to each subject.\n",
    "\n",
    "The features for this analysis contains the average signal intensity for each region determined by the AAL atlas. \n",
    "\n",
    "This notebook runs two tests to evaluate the accuracy of multiple classification models.\n",
    "1. Multi-class diagnosis (uses all diagnosis types)\n",
    "2. Binary classification (if subject has ADHD or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ecaa4",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the imports that are required for this notebook to run properly\n",
    "\n",
    "- `os` to access the file\n",
    "\n",
    "- `pandas` to work with dataframes\n",
    "\n",
    "- `numpy` for linear algebra\n",
    "\n",
    "- `train_test_split()` for splitting data into a training and testing set\n",
    "\n",
    "- `LogisticRegression` for a logistic regression machine learning model\n",
    "\n",
    "- `KNeighborsClassifier` for a KNN machine learning model\n",
    "\n",
    "- `SVC` for a SVM machine learning model\n",
    "\n",
    "- `LinearDiscriminantAnalysis` for a LDA machine learning model\n",
    "\n",
    "- `accuracy_score()` to evaluate the accuracy of the model\n",
    "\n",
    "- `StratifiedKFold, cross_valscore()` for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438daa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49dbab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62d93d",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "There are two basic functions that will be used to create the machine learning model\n",
    "\n",
    "1. get_base_filepath()\n",
    "\n",
    "2. extract_features()\n",
    "\n",
    "3. make_predictions()\n",
    "\n",
    "4. evaluate_models()\n",
    "\n",
    "5. get_accuracies()\n",
    "\n",
    "6. perform_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fc6b7",
   "metadata": {},
   "source": [
    "### get_base_filepath()\n",
    "\n",
    "Access the filepath for th ebase folder of the project. \n",
    "From here, any other asset of the project can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb3a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filepath():\n",
    "    '''\n",
    "    Access the filepath for the base folder of the project\n",
    "    \n",
    "    Input: None\n",
    "    \n",
    "    Output: The filepath to the root of the folder\n",
    "    '''\n",
    "    # Get current directory\n",
    "    os.path.abspath(os.curdir)\n",
    "\n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "\n",
    "    # Set baseline filepath to the project folder directory\n",
    "    base_folder_filepath = os.path.abspath(os.curdir)\n",
    "    return base_folder_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdb6d7",
   "metadata": {},
   "source": [
    "### extract_features()\n",
    "\n",
    "Create a dataframe using the mean of regions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2e873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filepath):\n",
    "    '''\n",
    "    Create a dataframe using the mean of regions over time.\n",
    "    \n",
    "    Input: filepath to open the dataframe\n",
    "    \n",
    "    Output: dataframe of mean for each region\n",
    "    '''\n",
    "    # Read the filepath as a dataframe (use 1 tab as separator and the first line as the header)\n",
    "    df = pd.read_csv(filepath, sep=r'\\s{1,}', engine='python', header=0)\n",
    "    \n",
    "    # Drop two features that get in the way of evaluation\n",
    "    df = df.drop('File', axis=1)\n",
    "    df = df.drop('Sub-brick', axis=1)\n",
    "    \n",
    "    # Return the mean for each of the features (method of vectorizing)\n",
    "    return df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2d03b",
   "metadata": {},
   "source": [
    "### make_predictions()\n",
    "\n",
    "Fit a model using the training data, \n",
    "make predictions on a testing set, \n",
    "and get the accuracy of the model.\n",
    "\n",
    "Used in evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7428f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, X_trn, X_tst, y_trn, y_tst):\n",
    "    '''\n",
    "    Get the accuracy of a model\n",
    "    \n",
    "    Input:\n",
    "        - A model to use to make predictions\n",
    "        - Set of training features\n",
    "        - Set of testing features\n",
    "        - Set of training targets\n",
    "        - Set of testing targets\n",
    "        \n",
    "    Output: Accuracy of the model\n",
    "    '''\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model_fit = model.fit(X_trn, y_trn)\n",
    "    \n",
    "    # Make predictions on the testing features\n",
    "    y_pred = model_fit.predict(X_tst)\n",
    "    \n",
    "    # Compare the predictions to the true values\n",
    "    accuracy = accuracy_score(y_pred, y_tst)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f640b6",
   "metadata": {},
   "source": [
    "### evaluate_models()\n",
    "\n",
    "Evaluate the performance of models on a set of features and targets.\n",
    "\n",
    "Uses make_predictions()\n",
    "\n",
    "Used in get_accuracies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a62cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y):\n",
    "    '''\n",
    "    Evaluate the performance of models on a set of features and targets.\n",
    "    \n",
    "    Input:\n",
    "        - Set of features\n",
    "        - Set of targets\n",
    "        \n",
    "    Output: Accuracy of three models (Logistic regression, KNN, SVM)\n",
    "    '''\n",
    "    # Separate the data into training and testing sets\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y)\n",
    "    \n",
    "    # Evaluate the accuracies using each of the three models\n",
    "    lr_acc = make_predictions(LogisticRegression(), X_trn, X_tst, y_trn, y_tst)\n",
    "    knn_acc = make_predictions(KNeighborsClassifier(), X_trn, X_tst, y_trn, y_tst)\n",
    "    svm_acc = make_predictions(SVC(), X_trn, X_tst, y_trn, y_tst)\n",
    "    lda_acc = make_predictions(LinearDiscriminantAnalysis(), X_trn, X_tst, y_trn, y_tst)\n",
    "    \n",
    "    # Return the accuracy in a list format\n",
    "    return [lr_acc, knn_acc, svm_acc, lda_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cdc526",
   "metadata": {},
   "source": [
    "### get_accuracies()\n",
    "\n",
    "Get 100 accuracies for three models (Logistic regression, KNN, SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b768664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(X, y):\n",
    "    '''\n",
    "    Get 100 accuracies for three models (Logistic regression, KNN, SVM).\n",
    "    \n",
    "    Input:\n",
    "        - Set of features\n",
    "        - Set of targets\n",
    "        \n",
    "    Output: List of 100 accuracies for the three models\n",
    "    '''\n",
    "    # Create an empty list to store the accuracies for each model\n",
    "    lr_acc = []\n",
    "    knn_acc = []\n",
    "    svm_acc = []\n",
    "    lda_acc = []\n",
    "    \n",
    "    # Run 100 iterations of evaluating the model\n",
    "    for i in range(100):\n",
    "        # Get the accuracy for this iteration\n",
    "        accuracies = evaluate_models(X, y)\n",
    "        \n",
    "        # Add it to the corresponding model holder\n",
    "        lr_acc.append(accuracies[0])\n",
    "        knn_acc.append(accuracies[1])\n",
    "        svm_acc.append(accuracies[2])\n",
    "        lda_acc.append(accuracies[3])\n",
    "        \n",
    "    # Return a list of all accuracies\n",
    "    return [lr_acc, knn_acc, svm_acc, lda_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2ecdd",
   "metadata": {},
   "source": [
    "### perform_cross_validation()\n",
    "\n",
    "Use a stratified K-fold for cross validation for the three classification models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507c5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(X_train, y_train):\n",
    "    '''\n",
    "    Input: \n",
    "        - A dataframe containing the features use to build the model\n",
    "        - A Series of the true values associated with the feature list\n",
    "    \n",
    "    Output: Printed result for the mean and standard deviation of each model\n",
    "    '''\n",
    "    # Create an empty dictionary to store the results\n",
    "    results = dict()\n",
    "\n",
    "    # Loop through the models\n",
    "    for name, model in models:\n",
    "        # Create a Stratified K-fold for cross validation\n",
    "        kfold = StratifiedKFold(n_splits=10)\n",
    "        \n",
    "        # Apply cross validation using the current model\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        \n",
    "        # Add the mean and standard deviation to the dictionary\n",
    "        results[name] = (cv_results.mean(), cv_results.std())\n",
    "\n",
    "    # Print the results\n",
    "    print('Model\\t\\tCV Mean\\t\\tCV std')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da4d41",
   "metadata": {},
   "source": [
    "## Open files\n",
    "\n",
    "In this section, the files for all of the patients is opened and combined into two matrices to build a dataframe in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d44b97",
   "metadata": {},
   "source": [
    "###  Filepaths\n",
    "\n",
    "Access the filepath to the preprocessed data folder. \n",
    "This is where the data for all of the sites are located.\n",
    "\n",
    "The filepath to the phenotypic data folder is also added here. \n",
    "This is where all of the phenotypic data files are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98771425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder for the project\n",
    "base_folder_filepath = get_base_filepath()\n",
    "\n",
    "# Preprocessed data site folder\n",
    "sites_filepath = base_folder_filepath +  '\\\\Data\\\\Preprocessed_data\\\\Sites\\\\'\n",
    "\n",
    "# Phenotypic data site folder\n",
    "phenotypics_filepath = base_folder_filepath + '\\\\Data\\\\Phenotypic\\\\Sites\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc9f06",
   "metadata": {},
   "source": [
    "### Subjects\n",
    "\n",
    "Open the 'sfnwmrda' file for each subject in the study. \n",
    "\n",
    "Add the features to a matrix and the subjects to a different matrix.\n",
    "\n",
    "There may be instances where the subject does not have the file in their folder. \n",
    "In this case, add the subject to a matrix to be dropped from the phenotypic dataframe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017bf29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty folder: 0010016\n",
      "Skipping empty folder: 0010027\n",
      "Skipping empty folder: 0010055\n",
      "Skipping empty folder: 0010098\n",
      "Skipping empty folder: 0010105\n",
      "Skipping empty folder: 0010127\n",
      "Skipping folder sfnwmrda0015001_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015004_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping empty folder: 0015011\n",
      "Skipping folder sfnwmrda0015016_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping empty folder: 0015018\n",
      "Skipping folder sfnwmrda0015026_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015027_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015032_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015036_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015052_session_1_rest_1_aal_TCs.1D: not found.\n",
      "Skipping folder sfnwmrda0015057_session_1_rest_1_aal_TCs.1D: not found.\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store important values\n",
    "subjects = []\n",
    "subject_features = []\n",
    "subjects_dropped = []\n",
    "\n",
    "# Loop through every site in the folder\n",
    "for site_folder in os.listdir(sites_filepath):\n",
    "    # Access the filepath to the site's folder\n",
    "    site_folder_path = os.path.join(sites_filepath, site_folder)\n",
    "        \n",
    "    # Loop through every patient in the site's folder\n",
    "    for patient_id_folder in os.listdir(site_folder_path):            \n",
    "        # Access the filepath to the patient's folder\n",
    "        patient_id_folder_path = os.path.join(site_folder_path, patient_id_folder)\n",
    "        \n",
    "        # Skip the folder if it is empty\n",
    "        if len(os.listdir(patient_id_folder_path)) == 0:\n",
    "            print(f\"Skipping empty folder: {patient_id_folder}\")\n",
    "            subjects_dropped.append(patient_id_folder)\n",
    "            continue\n",
    "\n",
    "        # Check if the filepath is a folder, continue if it is\n",
    "        if os.path.isdir(patient_id_folder_path):\n",
    "            # Get the file name (dependent on folder name)\n",
    "            file_name = f\"sfnwmrda{patient_id_folder}_session_1_rest_1_aal_TCs.1D\"\n",
    "            \n",
    "            # Join the file name to its path\n",
    "            file_path = os.path.join(patient_id_folder_path, file_name)\n",
    "            \n",
    "            # Skip the folder if the file is not in it\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Skipping folder {file_name}: not found.\")\n",
    "                subjects_dropped.append(patient_id_folder)\n",
    "                continue\n",
    "\n",
    "            # Extract the features and add it to the list of subjects\n",
    "            subject_features.append(extract_features(file_path))\n",
    "            \n",
    "            # Add the patient ID to the subjects list\n",
    "            subjects.append(patient_id_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a450316",
   "metadata": {},
   "source": [
    "### Diagnosis\n",
    "\n",
    "Open the phenotypic file for each subject in the study. \n",
    "\n",
    "Add the diagnosis to a matrix and the patient id to a different matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5a2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store important values\n",
    "dx = [] # For the diagnosis\n",
    "pheno_index = [] # For the patient id\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for site_pheno in os.listdir(phenotypics_filepath):\n",
    "    # Access the filepath to the phenotypic data\n",
    "    site_pheno_filepath = os.path.join(phenotypics_filepath, site_pheno)\n",
    "    \n",
    "    # Check if the current item in the directory is a file\n",
    "    if os.path.isfile(site_pheno_filepath):\n",
    "        # Read the file as a dataframe\n",
    "        df_pheno = pd.read_csv(site_pheno_filepath, index_col='ScanDir ID')\n",
    "        \n",
    "        # Add the diagnosis to the list\n",
    "        dx.append(df_pheno['DX'])\n",
    "        \n",
    "        # Add the patient id to the list\n",
    "        pheno_index.append(df_pheno.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eddd5d",
   "metadata": {},
   "source": [
    "## Build the dataframe\n",
    "\n",
    "Create a dataframe of the subjects, regions and their diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e87dd",
   "metadata": {},
   "source": [
    "### Subject x Region\n",
    "\n",
    "Build a matrix of subjects vs. regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7d35d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_2001</th>\n",
       "      <th>Mean_2002</th>\n",
       "      <th>Mean_2101</th>\n",
       "      <th>Mean_2102</th>\n",
       "      <th>Mean_2111</th>\n",
       "      <th>Mean_2112</th>\n",
       "      <th>Mean_2201</th>\n",
       "      <th>Mean_2202</th>\n",
       "      <th>Mean_2211</th>\n",
       "      <th>Mean_2212</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_9081</th>\n",
       "      <th>Mean_9082</th>\n",
       "      <th>Mean_9100</th>\n",
       "      <th>Mean_9110</th>\n",
       "      <th>Mean_9120</th>\n",
       "      <th>Mean_9130</th>\n",
       "      <th>Mean_9140</th>\n",
       "      <th>Mean_9150</th>\n",
       "      <th>Mean_9160</th>\n",
       "      <th>Mean_9170</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010001</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010002</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.004370</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010003</th>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>-0.007068</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>-0.011144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010004</th>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.003498</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.004143</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.005601</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010005</th>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.007235</td>\n",
       "      <td>-0.008659</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.001598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean_2001  Mean_2002  Mean_2101  Mean_2102  Mean_2111  Mean_2112   \n",
       "0010001   0.001918   0.001396   0.000917   0.001579   0.001620   0.000398  \\\n",
       "0010002   0.000535  -0.000911  -0.004370   0.000013  -0.012312   0.001798   \n",
       "0010003   0.004598   0.001763   0.001807  -0.000461  -0.004121  -0.007068   \n",
       "0010004  -0.000559   0.000830  -0.003498  -0.001282  -0.004143   0.001574   \n",
       "0010005   0.003364   0.006273   0.014627   0.015924   0.000704   0.002034   \n",
       "\n",
       "         Mean_2201  Mean_2202  Mean_2211  Mean_2212  ...  Mean_9081   \n",
       "0010001   0.000401   0.000248  -0.000006  -0.001791  ...  -0.001946  \\\n",
       "0010002  -0.001885   0.000525  -0.002277   0.015622  ...  -0.000176   \n",
       "0010003   0.003899   0.004255  -0.001597  -0.011144  ...  -0.001121   \n",
       "0010004  -0.001477  -0.000162  -0.005601   0.002853  ...   0.000800   \n",
       "0010005   0.016690   0.014993   0.004241   0.008220  ...   0.007601   \n",
       "\n",
       "         Mean_9082  Mean_9100  Mean_9110  Mean_9120  Mean_9130  Mean_9140   \n",
       "0010001  -0.001540   0.002221   0.001640  -0.000227  -0.000473  -0.000525  \\\n",
       "0010002  -0.001465  -0.002169  -0.000968   0.001107   0.001050   0.000374   \n",
       "0010003  -0.001566  -0.009230  -0.002198   0.006707   0.009246  -0.000108   \n",
       "0010004  -0.000904  -0.000326   0.000155   0.003007   0.001742   0.002644   \n",
       "0010005   0.004895   0.001707  -0.004593  -0.007235  -0.008659  -0.007546   \n",
       "\n",
       "         Mean_9150  Mean_9160  Mean_9170  \n",
       "0010001   0.002460   0.001810  -0.000823  \n",
       "0010002  -0.000629  -0.000025   0.001806  \n",
       "0010003   0.001620  -0.000059  -0.007794  \n",
       "0010004   0.000302  -0.000304  -0.000530  \n",
       "0010005  -0.000393  -0.003564  -0.001598  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Turn the array of features into a dataframe with the index as the subject id\n",
    "df_subject_x_region = pd.DataFrame(subject_features, index=subjects)\n",
    "df_subject_x_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867ce73",
   "metadata": {},
   "source": [
    "# Multi-Class Classificaiton\n",
    "\n",
    "This section investigates how models perform when predicting the type of ADHD the subject has or if they are a control.\n",
    "\n",
    "This is accomplished by extracting the diagnosis from the phenotypic data and adding it to the regions. \n",
    "Each number corresponds to a type diagnosis for ADHD.\n",
    "\n",
    "    0 = TDC (Typically developing children)\n",
    "    1 = ADHD-Combined\n",
    "    2 = ADHD-Hyperactive/Impulsive\n",
    "    3 = ADHD-Inattentive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a88ba",
   "metadata": {},
   "source": [
    "### Diagnosis Series\n",
    "\n",
    "Create a series of the patient diagnosis to combine with the region dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e89be6",
   "metadata": {},
   "source": [
    "Make a vector of the patient ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e88a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condense the indicies in the phenotypic data to a vector\n",
    "patient_ids = [p_id for site_pheno in pheno_index for p_id in site_pheno]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb70421",
   "metadata": {},
   "source": [
    "Unify patient id formatting and create a series for the diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac8f7ac2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fix some of the patient ids\n",
    "for i in range (len(patient_ids)):\n",
    "    # Access the current patient id\n",
    "    s_id = patient_ids[i]\n",
    "    \n",
    "    # If the length of the patient id is 5...\n",
    "    if len(str(s_id)) == 5:\n",
    "        # ... add '00' to the beginning to match formatting with the folder names\n",
    "        patient_ids[i] = '00' + str(s_id)\n",
    "        \n",
    "    # Otherwise, turn the current id into a string value\n",
    "    else:\n",
    "        patient_ids[i] = str(s_id)\n",
    "    \n",
    "# Make the diagnosis a series with the phenotypic array as the index\n",
    "diagnosis = pd.Series([diag for site_pheno in dx for diag in site_pheno], index=patient_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be3dfc",
   "metadata": {},
   "source": [
    "### Combine\n",
    "\n",
    "Add the diagnosis Series to the regions dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26439d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_2001</th>\n",
       "      <th>Mean_2002</th>\n",
       "      <th>Mean_2101</th>\n",
       "      <th>Mean_2102</th>\n",
       "      <th>Mean_2111</th>\n",
       "      <th>Mean_2112</th>\n",
       "      <th>Mean_2201</th>\n",
       "      <th>Mean_2202</th>\n",
       "      <th>Mean_2211</th>\n",
       "      <th>Mean_2212</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_9082</th>\n",
       "      <th>Mean_9100</th>\n",
       "      <th>Mean_9110</th>\n",
       "      <th>Mean_9120</th>\n",
       "      <th>Mean_9130</th>\n",
       "      <th>Mean_9140</th>\n",
       "      <th>Mean_9150</th>\n",
       "      <th>Mean_9160</th>\n",
       "      <th>Mean_9170</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010001</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010002</th>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.004370</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.002277</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010003</th>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-0.004121</td>\n",
       "      <td>-0.007068</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>-0.011144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>-0.002198</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010004</th>\n",
       "      <td>-0.000559</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.003498</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.004143</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.005601</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010005</th>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>-0.007235</td>\n",
       "      <td>-0.008659</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean_2001  Mean_2002  Mean_2101  Mean_2102  Mean_2111  Mean_2112   \n",
       "0010001   0.001918   0.001396   0.000917   0.001579   0.001620   0.000398  \\\n",
       "0010002   0.000535  -0.000911  -0.004370   0.000013  -0.012312   0.001798   \n",
       "0010003   0.004598   0.001763   0.001807  -0.000461  -0.004121  -0.007068   \n",
       "0010004  -0.000559   0.000830  -0.003498  -0.001282  -0.004143   0.001574   \n",
       "0010005   0.003364   0.006273   0.014627   0.015924   0.000704   0.002034   \n",
       "\n",
       "         Mean_2201  Mean_2202  Mean_2211  Mean_2212  ...  Mean_9082   \n",
       "0010001   0.000401   0.000248  -0.000006  -0.001791  ...  -0.001540  \\\n",
       "0010002  -0.001885   0.000525  -0.002277   0.015622  ...  -0.001465   \n",
       "0010003   0.003899   0.004255  -0.001597  -0.011144  ...  -0.001566   \n",
       "0010004  -0.001477  -0.000162  -0.005601   0.002853  ...  -0.000904   \n",
       "0010005   0.016690   0.014993   0.004241   0.008220  ...   0.004895   \n",
       "\n",
       "         Mean_9100  Mean_9110  Mean_9120  Mean_9130  Mean_9140  Mean_9150   \n",
       "0010001   0.002221   0.001640  -0.000227  -0.000473  -0.000525   0.002460  \\\n",
       "0010002  -0.002169  -0.000968   0.001107   0.001050   0.000374  -0.000629   \n",
       "0010003  -0.009230  -0.002198   0.006707   0.009246  -0.000108   0.001620   \n",
       "0010004  -0.000326   0.000155   0.003007   0.001742   0.002644   0.000302   \n",
       "0010005   0.001707  -0.004593  -0.007235  -0.008659  -0.007546  -0.000393   \n",
       "\n",
       "         Mean_9160  Mean_9170  DX  \n",
       "0010001   0.001810  -0.000823   3  \n",
       "0010002  -0.000025   0.001806   3  \n",
       "0010003  -0.000059  -0.007794   0  \n",
       "0010004  -0.000304  -0.000530   0  \n",
       "0010005  -0.003564  -0.001598   2  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of the region dataframe\n",
    "df_region_w_dx = df_subject_x_region.copy()\n",
    "\n",
    "# Drop the rows with missing files or folders from the Series\n",
    "filtered_diagnosis = diagnosis.drop(index=subjects_dropped)\n",
    "\n",
    "# Add the diagnosis to the region dataframe\n",
    "df_region_w_dx['DX'] = filtered_diagnosis\n",
    "\n",
    "df_region_w_dx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01744941",
   "metadata": {},
   "source": [
    "View the number of unique types of diagnosis in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fb61023",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DX\n",
       "0    395\n",
       "1    125\n",
       "3    104\n",
       "2      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region_w_dx['DX'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d28d3",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy\n",
    "\n",
    "Build models and evaluate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7bdb1",
   "metadata": {},
   "source": [
    "Separate dataframe into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be777f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_region_w_dx.drop('DX', axis=1)\n",
    "y = df_region_w_dx['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820449a",
   "metadata": {},
   "source": [
    "Get 100 accuracies for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93324439",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = get_accuracies(X, y)\n",
    "accuracies = np.asarray(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e5b2a",
   "metadata": {},
   "source": [
    "Get statistics describing accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f0f736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [accuracies[0].mean(), accuracies[1].mean(), accuracies[2].mean(), accuracies[3].mean()]\n",
    "stds  = [accuracies[0].std(),  accuracies[1].std(),  accuracies[2].std(),  accuracies[2].std()]\n",
    "maxes = [accuracies[0].max(),  accuracies[1].max(),  accuracies[2].max(),  accuracies[2].max()]\n",
    "mins  = [accuracies[0].min(),  accuracies[1].min(),  accuracies[2].min(),  accuracies[2].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88abfa7c",
   "metadata": {},
   "source": [
    "Turn the statistics into a dataframe for simpler analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37f2ca4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.625860</td>\n",
       "      <td>0.575987</td>\n",
       "      <td>0.625860</td>\n",
       "      <td>0.531720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.035195</td>\n",
       "      <td>0.032989</td>\n",
       "      <td>0.035195</td>\n",
       "      <td>0.035195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.713376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.503185</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.541401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR       KNN       SVM       LDA\n",
       "Mean  0.625860  0.575987  0.625860  0.531720\n",
       "STD   0.035195  0.032989  0.035195  0.035195\n",
       "Max   0.713376  0.649682  0.713376  0.713376\n",
       "Min   0.541401  0.503185  0.541401  0.541401"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([means, stds, maxes, mins], index=['Mean', 'STD', 'Max', 'Min'], columns=['LR', 'KNN', 'SVM', 'LDA'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adcedbf",
   "metadata": {},
   "source": [
    "Perform cross validation to compare this to the 100 iteration method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f90600b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.6290066564260113, 0.008930862894101646), 'KNN': (0.5734511008704557, 0.07671529589607275), 'SVM': (0.6290066564260113, 0.008930862894101646), 'LDA': (0.5446748591909883, 0.09721729643657481)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48722a",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57615efa",
   "metadata": {},
   "source": [
    "# Binary Classificaiton\n",
    "\n",
    "This section investigates how models perform when predicting whether a patient has ADHD or not. \n",
    "\n",
    "This is accomplished by converting the diagnosis to a binary value based on if their diagnosis is a control or has some type of ADHD. \n",
    "For this feature, 'True' signifies the subject has ADHD and 'False' signifies the subject is a control and does not have ADHD.\n",
    "\n",
    "Theoretically, this model should perform better than the multi-class classification since it is simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a78b56",
   "metadata": {},
   "source": [
    "## Build the dataframe\n",
    "\n",
    "Create a dataframe of the subjects, regions and their diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef816fe",
   "metadata": {},
   "source": [
    "Make the diagnosis a series with the phenotypic array as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c06fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the binary classification for each diagnosis to a Series\n",
    "diagnosis_binary = pd.Series([diag>0 for site_pheno in dx for diag in site_pheno], index=patient_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b36e43",
   "metadata": {},
   "source": [
    "### Combine\n",
    "\n",
    "Add the diagnosis Series to the regions dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3334c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the region dataframe\n",
    "df_region_w_dx_binary = df_subject_x_region.copy()\n",
    "\n",
    "# Drop the rows with missing files or folders from the Series\n",
    "filtered_diagnosis_binary = diagnosis_binary.drop(index=subjects_dropped)\n",
    "\n",
    "# Add the diagnosis to the region dataframe\n",
    "df_region_w_dx_binary['DX'] = filtered_diagnosis_binary\n",
    "\n",
    "df_region_w_dx_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416005a",
   "metadata": {},
   "source": [
    "View the number of subjects with and without ADHD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3d3bfa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DX\n",
       "False    395\n",
       "True     233\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region_w_dx_binary['DX'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4d9ea",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy\n",
    "\n",
    "Build models and evaluate the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37302f7",
   "metadata": {},
   "source": [
    "Separate dataframe into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd054f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_region_w_dx_binary.drop('DX', axis=1)\n",
    "y_binary = df_region_w_dx_binary['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed641c",
   "metadata": {},
   "source": [
    "Get 100 accuracies for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "442c5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_binary = get_accuracies(X_binary, y_binary)\n",
    "accuracies_binary = np.asarray(accs_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2df4e",
   "metadata": {},
   "source": [
    "Get statistics describing accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "594533e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_binary = [accuracies_binary[0].mean(), accuracies_binary[1].mean(), accuracies_binary[2].mean(), accuracies_binary[3].mean()]\n",
    "stds_binary  = [accuracies_binary[0].std(),  accuracies_binary[1].std(),  accuracies_binary[2].std(),  accuracies_binary[2].std()]\n",
    "maxes_binary = [accuracies_binary[0].max(),  accuracies_binary[1].max(),  accuracies_binary[2].max(),  accuracies_binary[2].max()]\n",
    "mins_binary  = [accuracies_binary[0].min(),  accuracies_binary[1].min(),  accuracies_binary[2].min(),  accuracies_binary[2].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47323e4e",
   "metadata": {},
   "source": [
    "Turn the statistics into a dataframe for simpler analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e0655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.631975</td>\n",
       "      <td>0.609363</td>\n",
       "      <td>0.628408</td>\n",
       "      <td>0.605732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.033578</td>\n",
       "      <td>0.025606</td>\n",
       "      <td>0.035683</td>\n",
       "      <td>0.035683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.713376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.535032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR       KNN       SVM       LDA\n",
       "Mean  0.631975  0.609363  0.628408  0.605732\n",
       "STD   0.033578  0.025606  0.035683  0.035683\n",
       "Max   0.700637  0.668790  0.713376  0.713376\n",
       "Min   0.541401  0.535032  0.535032  0.535032"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_binary = pd.DataFrame([means_binary, stds_binary, maxes_binary, mins_binary], \n",
    "                              index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                              columns=['LR', 'KNN', 'SVM', 'LDA'])\n",
    "results_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df08a5",
   "metadata": {},
   "source": [
    "Perform cross validation to compare this to the 100 iteration method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "122001c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.6289810547875063, 0.006873265171196576), 'KNN': (0.5992319508448541, 0.13676682837438184), 'SVM': (0.5892985151049667, 0.0646063625037743), 'LDA': (0.6038402457757297, 0.12265302274632825)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X_binary, y_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
