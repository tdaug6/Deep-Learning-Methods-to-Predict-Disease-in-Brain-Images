{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b527c2",
   "metadata": {},
   "source": [
    "# Correlation Matrices with OHSU\n",
    "\n",
    "This notebook investigates the Pearson's correlation matrices for subjects from the OHSU site.\n",
    "\n",
    "First the image data for each subject is combined into a single dataframe (subject x region correlation)\n",
    "\n",
    "Next, the diagnosis for the patient is added for the corresponding subject.\n",
    "\n",
    "Finally, a machine learning model is trained on the dataframe and the predictions are compared to the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b5da19",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the imports that are required for this notebook to run properly\n",
    "\n",
    "- `os` to access the file\n",
    "\n",
    "- `pandas` to work with dataframes\n",
    "\n",
    "- `numpy` for linear algebra\n",
    "\n",
    "- `seaborn` for nicer looking graphs\n",
    "\n",
    "- `matplotlib.pyplot` for graphing the matrix\n",
    "\n",
    "- `train_test_split()` for splitting data into a training and testing set\n",
    "\n",
    "- `LogisticRegression` for a logistic regression machine learning model\n",
    "\n",
    "- `KNeighborsClassifier` for a KNN machine learning model\n",
    "\n",
    "- `SVC` for a SVM machine learning model\n",
    "\n",
    "- `accuracy_score()` to evaluate the accuracy of the model\n",
    "\n",
    "- `StratifiedKFold, cross_valscore()` for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf627d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450512ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf13634",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "There are two basic functions that will be used to create the machine learning model\n",
    "\n",
    "1. get_base_filepath()\n",
    "\n",
    "2. extract_features()\n",
    "\n",
    "3. perform_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7615d98",
   "metadata": {},
   "source": [
    "### get_base_filepath()\n",
    "\n",
    "Access the filepath for th ebase folder of the project. \n",
    "From here, any other asset of the project can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948a3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filepath():\n",
    "    '''\n",
    "    Access the filepath for the base folder of the project\n",
    "    \n",
    "    Input: None\n",
    "    \n",
    "    Output: The filepath to the root of the folder\n",
    "    '''\n",
    "    # Get current directory\n",
    "    os.path.abspath(os.curdir)\n",
    "\n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "\n",
    "    # Set baseline filepath to the project folder directory\n",
    "    base_folder_filepath = os.path.abspath(os.curdir)\n",
    "    return base_folder_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46549873",
   "metadata": {},
   "source": [
    "### extract_features()\n",
    "\n",
    "Create a dataframe using the mean of regions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ff3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filepath):\n",
    "    '''\n",
    "    Create a dataframe correlation of the regions over time\n",
    "    \n",
    "    Input: filepath to open the dataframe\n",
    "    \n",
    "    Output: dataframe of correlations between region\n",
    "    '''\n",
    "    # Read the filepath as a dataframe (use 1 tab as separator and the first line as the header)\n",
    "    df = pd.read_csv(filepath, sep=r'\\s{1,}', engine='python', header=0)\n",
    "    \n",
    "    # Drop two features that get in the way of evaluation\n",
    "    df = df.drop('File', axis=1)\n",
    "    df = df.drop('Sub-brick', axis=1)\n",
    "    \n",
    "    # Get the correlation matrix of the dataframe\n",
    "    cor = df.corr()\n",
    "    \n",
    "    # Create an empty list to store the correlations\n",
    "    corr_vector = []\n",
    "    \n",
    "    # Loop through every row in the dataframe\n",
    "    for row in range(len(cor.index)):\n",
    "        # Loop through every feature in the dataframe\n",
    "        for feature in range(len(cor.columns)):\n",
    "            # Exclude unwanted values\n",
    "            #    1 when row number = feature number\n",
    "            #    repeat when row number > feature number\n",
    "            if row >= feature:\n",
    "                continue\n",
    "            \n",
    "            # Add the correlation value to the vector\n",
    "            corr_vector.append(cor.iloc[row, feature])\n",
    "    \n",
    "    # Return the correlation for each of the regions (method of vectorizing)\n",
    "    return corr_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f4c0a",
   "metadata": {},
   "source": [
    "### perform_cross_validation()\n",
    "\n",
    "Use a stratified K-fold for cross validation for the three classification models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c04a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(X_train, y_train):\n",
    "    '''\n",
    "    Input: \n",
    "        - A dataframe containing the features use to build the model\n",
    "        - A Series of the true values associated with the feature list\n",
    "    \n",
    "    Output: Printed result for the mean and standard deviation of each model\n",
    "    '''\n",
    "    # Create an empty dictionary to store the results\n",
    "    results = dict()\n",
    "\n",
    "    # Loop through the models\n",
    "    for name, model in models:\n",
    "        # Create a Stratified K-fold for cross validation\n",
    "        kfold = StratifiedKFold(n_splits=10)\n",
    "        \n",
    "        # Apply cross validation using the current model\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        \n",
    "        # Add the mean and standard deviation to the dictionary\n",
    "        results[name] = (cv_results.mean(), cv_results.std())\n",
    "\n",
    "    # Print the results\n",
    "    print('Model\\t\\tCV Mean\\t\\tCV std')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc1386",
   "metadata": {},
   "source": [
    "## Open files\n",
    "\n",
    "In this section, the files for all of the patients is opened and combined into two matrices to build a dataframe in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ae6e9",
   "metadata": {},
   "source": [
    "###  Filepaths\n",
    "\n",
    "Access the filepath to the OHSU folder. \n",
    "This is where the data for all of the patients at the OHSU site are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2007af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder_filepath = get_base_filepath()\n",
    "ohsu_filepath = base_folder_filepath +  '\\\\Data\\\\Preprocessed_data\\\\Sites\\\\OHSU\\\\'\n",
    "phenotypics_filepath = base_folder_filepath + '\\\\Data\\\\Phenotypic\\\\Sites\\\\OHSU_phenotypic.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419e973",
   "metadata": {},
   "source": [
    "### Subjects\n",
    "\n",
    "Open the 'sfnwmrda' file for each subject at the OHSU site. \n",
    "\n",
    "Add the features to a matrix and the subjects to a different matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e1a7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "subject_features = []\n",
    "\n",
    "# Access all sfnwmrda files in the OHSU folder\n",
    "# Access the patient folders within the site folder\n",
    "for patient_id_folder in os.listdir(ohsu_filepath):\n",
    "    # Access the filepath to the folder\n",
    "    patient_id_folder_path = os.path.join(ohsu_filepath, patient_id_folder)\n",
    "    \n",
    "    subjects.append(patient_id_folder)\n",
    "    \n",
    "    # Check if the filepath is a folder, continue if it is a folder\n",
    "    if os.path.isdir(patient_id_folder_path):\n",
    "        # Get the file name (dependent on folder name)\n",
    "        file_name = f\"sfnwmrda{patient_id_folder}_session_1_rest_1_aal_TCs.1D\"\n",
    "        \n",
    "        # Join the file name to its path\n",
    "        file_path = os.path.join(patient_id_folder_path, file_name)\n",
    "        \n",
    "        # Extract the features and add it to the list of subjects\n",
    "        subject_features.append(extract_features(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a599741",
   "metadata": {},
   "source": [
    "## Build the dataframe\n",
    "\n",
    "Using the subjects, their features, and their phenotypics, create a dataframe of subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8f261",
   "metadata": {},
   "source": [
    "### Subject x Region Correlation\n",
    "\n",
    "Using the code from the previous cell, build a matrix of subjects vs. region correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5731c282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6660</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084283</th>\n",
       "      <td>0.627503</td>\n",
       "      <td>0.102603</td>\n",
       "      <td>0.202119</td>\n",
       "      <td>-0.253194</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.262696</td>\n",
       "      <td>0.676474</td>\n",
       "      <td>0.199277</td>\n",
       "      <td>0.203969</td>\n",
       "      <td>0.443223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698502</td>\n",
       "      <td>0.732939</td>\n",
       "      <td>0.039584</td>\n",
       "      <td>-0.599000</td>\n",
       "      <td>0.817161</td>\n",
       "      <td>0.010360</td>\n",
       "      <td>-0.732348</td>\n",
       "      <td>0.232411</td>\n",
       "      <td>-0.584458</td>\n",
       "      <td>0.297212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084884</th>\n",
       "      <td>0.616312</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>-0.261927</td>\n",
       "      <td>-0.063935</td>\n",
       "      <td>0.162726</td>\n",
       "      <td>0.054850</td>\n",
       "      <td>0.203061</td>\n",
       "      <td>0.482815</td>\n",
       "      <td>0.338529</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742337</td>\n",
       "      <td>0.461013</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>-0.229072</td>\n",
       "      <td>0.629281</td>\n",
       "      <td>-0.021019</td>\n",
       "      <td>-0.159160</td>\n",
       "      <td>0.561103</td>\n",
       "      <td>0.480508</td>\n",
       "      <td>0.896453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108916</th>\n",
       "      <td>0.794140</td>\n",
       "      <td>-0.342100</td>\n",
       "      <td>0.231283</td>\n",
       "      <td>-0.473526</td>\n",
       "      <td>-0.262899</td>\n",
       "      <td>-0.193719</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>-0.292466</td>\n",
       "      <td>-0.121465</td>\n",
       "      <td>0.347377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615086</td>\n",
       "      <td>0.331752</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>-0.353265</td>\n",
       "      <td>0.565515</td>\n",
       "      <td>0.246508</td>\n",
       "      <td>-0.168515</td>\n",
       "      <td>0.712120</td>\n",
       "      <td>0.212148</td>\n",
       "      <td>0.532709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206380</th>\n",
       "      <td>0.683042</td>\n",
       "      <td>0.400591</td>\n",
       "      <td>0.050560</td>\n",
       "      <td>0.399696</td>\n",
       "      <td>-0.205624</td>\n",
       "      <td>-0.066348</td>\n",
       "      <td>-0.422396</td>\n",
       "      <td>-0.077063</td>\n",
       "      <td>-0.083302</td>\n",
       "      <td>0.146099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565635</td>\n",
       "      <td>0.467435</td>\n",
       "      <td>-0.348167</td>\n",
       "      <td>-0.300269</td>\n",
       "      <td>0.595721</td>\n",
       "      <td>-0.011787</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>0.280008</td>\n",
       "      <td>0.213431</td>\n",
       "      <td>0.818195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340333</th>\n",
       "      <td>0.930560</td>\n",
       "      <td>-0.405752</td>\n",
       "      <td>-0.420236</td>\n",
       "      <td>-0.130116</td>\n",
       "      <td>0.095078</td>\n",
       "      <td>0.127039</td>\n",
       "      <td>0.291338</td>\n",
       "      <td>-0.003459</td>\n",
       "      <td>0.190546</td>\n",
       "      <td>0.675852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556788</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.076717</td>\n",
       "      <td>0.312111</td>\n",
       "      <td>0.487547</td>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.197871</td>\n",
       "      <td>0.708691</td>\n",
       "      <td>0.147649</td>\n",
       "      <td>0.297182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6      \n",
       "1084283  0.627503  0.102603  0.202119 -0.253194  0.020725  0.262696  0.676474  \\\n",
       "1084884  0.616312 -0.004942 -0.261927 -0.063935  0.162726  0.054850  0.203061   \n",
       "1108916  0.794140 -0.342100  0.231283 -0.473526 -0.262899 -0.193719  0.037132   \n",
       "1206380  0.683042  0.400591  0.050560  0.399696 -0.205624 -0.066348 -0.422396   \n",
       "1340333  0.930560 -0.405752 -0.420236 -0.130116  0.095078  0.127039  0.291338   \n",
       "\n",
       "             7         8         9     ...      6660      6661      6662   \n",
       "1084283  0.199277  0.203969  0.443223  ...  0.698502  0.732939  0.039584  \\\n",
       "1084884  0.482815  0.338529  0.764273  ...  0.742337  0.461013 -0.010316   \n",
       "1108916 -0.292466 -0.121465  0.347377  ...  0.615086  0.331752 -0.033449   \n",
       "1206380 -0.077063 -0.083302  0.146099  ...  0.565635  0.467435 -0.348167   \n",
       "1340333 -0.003459  0.190546  0.675852  ...  0.556788  0.371579  0.076717   \n",
       "\n",
       "             6663      6664      6665      6666      6667      6668      6669  \n",
       "1084283 -0.599000  0.817161  0.010360 -0.732348  0.232411 -0.584458  0.297212  \n",
       "1084884 -0.229072  0.629281 -0.021019 -0.159160  0.561103  0.480508  0.896453  \n",
       "1108916 -0.353265  0.565515  0.246508 -0.168515  0.712120  0.212148  0.532709  \n",
       "1206380 -0.300269  0.595721 -0.011787  0.079066  0.280008  0.213431  0.818195  \n",
       "1340333  0.312111  0.487547  0.057883  0.197871  0.708691  0.147649  0.297182  \n",
       "\n",
       "[5 rows x 6670 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subject_x_region = pd.DataFrame(subject_features, index=subjects)\n",
    "df_subject_x_region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d28a6a2",
   "metadata": {},
   "source": [
    "### Diagnosis\n",
    "\n",
    "Add the subject's diagnosis to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827d118",
   "metadata": {},
   "source": [
    "Read the phenotypic file as a dataframe.\n",
    "\n",
    "Extract the diagnosis as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba2c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenotypic = pd.read_csv(phenotypics_filepath, index_col='ScanDir ID')\n",
    "diagnosis = df_phenotypic['DX'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffe254",
   "metadata": {},
   "source": [
    "Add the diagnosis to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956a364b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6661</th>\n",
       "      <th>6662</th>\n",
       "      <th>6663</th>\n",
       "      <th>6664</th>\n",
       "      <th>6665</th>\n",
       "      <th>6666</th>\n",
       "      <th>6667</th>\n",
       "      <th>6668</th>\n",
       "      <th>6669</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084283</th>\n",
       "      <td>0.627503</td>\n",
       "      <td>0.102603</td>\n",
       "      <td>0.202119</td>\n",
       "      <td>-0.253194</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>0.262696</td>\n",
       "      <td>0.676474</td>\n",
       "      <td>0.199277</td>\n",
       "      <td>0.203969</td>\n",
       "      <td>0.443223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732939</td>\n",
       "      <td>0.039584</td>\n",
       "      <td>-0.599000</td>\n",
       "      <td>0.817161</td>\n",
       "      <td>0.010360</td>\n",
       "      <td>-0.732348</td>\n",
       "      <td>0.232411</td>\n",
       "      <td>-0.584458</td>\n",
       "      <td>0.297212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084884</th>\n",
       "      <td>0.616312</td>\n",
       "      <td>-0.004942</td>\n",
       "      <td>-0.261927</td>\n",
       "      <td>-0.063935</td>\n",
       "      <td>0.162726</td>\n",
       "      <td>0.054850</td>\n",
       "      <td>0.203061</td>\n",
       "      <td>0.482815</td>\n",
       "      <td>0.338529</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461013</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>-0.229072</td>\n",
       "      <td>0.629281</td>\n",
       "      <td>-0.021019</td>\n",
       "      <td>-0.159160</td>\n",
       "      <td>0.561103</td>\n",
       "      <td>0.480508</td>\n",
       "      <td>0.896453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108916</th>\n",
       "      <td>0.794140</td>\n",
       "      <td>-0.342100</td>\n",
       "      <td>0.231283</td>\n",
       "      <td>-0.473526</td>\n",
       "      <td>-0.262899</td>\n",
       "      <td>-0.193719</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>-0.292466</td>\n",
       "      <td>-0.121465</td>\n",
       "      <td>0.347377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331752</td>\n",
       "      <td>-0.033449</td>\n",
       "      <td>-0.353265</td>\n",
       "      <td>0.565515</td>\n",
       "      <td>0.246508</td>\n",
       "      <td>-0.168515</td>\n",
       "      <td>0.712120</td>\n",
       "      <td>0.212148</td>\n",
       "      <td>0.532709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206380</th>\n",
       "      <td>0.683042</td>\n",
       "      <td>0.400591</td>\n",
       "      <td>0.050560</td>\n",
       "      <td>0.399696</td>\n",
       "      <td>-0.205624</td>\n",
       "      <td>-0.066348</td>\n",
       "      <td>-0.422396</td>\n",
       "      <td>-0.077063</td>\n",
       "      <td>-0.083302</td>\n",
       "      <td>0.146099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467435</td>\n",
       "      <td>-0.348167</td>\n",
       "      <td>-0.300269</td>\n",
       "      <td>0.595721</td>\n",
       "      <td>-0.011787</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>0.280008</td>\n",
       "      <td>0.213431</td>\n",
       "      <td>0.818195</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340333</th>\n",
       "      <td>0.930560</td>\n",
       "      <td>-0.405752</td>\n",
       "      <td>-0.420236</td>\n",
       "      <td>-0.130116</td>\n",
       "      <td>0.095078</td>\n",
       "      <td>0.127039</td>\n",
       "      <td>0.291338</td>\n",
       "      <td>-0.003459</td>\n",
       "      <td>0.190546</td>\n",
       "      <td>0.675852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.076717</td>\n",
       "      <td>0.312111</td>\n",
       "      <td>0.487547</td>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.197871</td>\n",
       "      <td>0.708691</td>\n",
       "      <td>0.147649</td>\n",
       "      <td>0.297182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6   \n",
       "1084283  0.627503  0.102603  0.202119 -0.253194  0.020725  0.262696  0.676474  \\\n",
       "1084884  0.616312 -0.004942 -0.261927 -0.063935  0.162726  0.054850  0.203061   \n",
       "1108916  0.794140 -0.342100  0.231283 -0.473526 -0.262899 -0.193719  0.037132   \n",
       "1206380  0.683042  0.400591  0.050560  0.399696 -0.205624 -0.066348 -0.422396   \n",
       "1340333  0.930560 -0.405752 -0.420236 -0.130116  0.095078  0.127039  0.291338   \n",
       "\n",
       "                7         8         9  ...      6661      6662      6663   \n",
       "1084283  0.199277  0.203969  0.443223  ...  0.732939  0.039584 -0.599000  \\\n",
       "1084884  0.482815  0.338529  0.764273  ...  0.461013 -0.010316 -0.229072   \n",
       "1108916 -0.292466 -0.121465  0.347377  ...  0.331752 -0.033449 -0.353265   \n",
       "1206380 -0.077063 -0.083302  0.146099  ...  0.467435 -0.348167 -0.300269   \n",
       "1340333 -0.003459  0.190546  0.675852  ...  0.371579  0.076717  0.312111   \n",
       "\n",
       "             6664      6665      6666      6667      6668      6669  DX  \n",
       "1084283  0.817161  0.010360 -0.732348  0.232411 -0.584458  0.297212   1  \n",
       "1084884  0.629281 -0.021019 -0.159160  0.561103  0.480508  0.896453   0  \n",
       "1108916  0.565515  0.246508 -0.168515  0.712120  0.212148  0.532709   1  \n",
       "1206380  0.595721 -0.011787  0.079066  0.280008  0.213431  0.818195   3  \n",
       "1340333  0.487547  0.057883  0.197871  0.708691  0.147649  0.297182   1  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region_w_dx = df_subject_x_region.copy()\n",
    "\n",
    "df_region_w_dx['DX'] = diagnosis\n",
    "\n",
    "df_region_w_dx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eaffbc",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Build a machine learning model and use it to make predictions on the dataset. \n",
    "Evaluate the model based on its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32da37",
   "metadata": {},
   "source": [
    "Separate the data into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c450727",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_region_w_dx.drop('DX', axis=1)\n",
    "y = df_region_w_dx['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b116887",
   "metadata": {},
   "source": [
    "### Build a model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074fc642",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9d4d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR = LogisticRegression().fit(X, y)\n",
    "y_pred_LR = model_LR.predict(X)\n",
    "\n",
    "accuracy_LR = accuracy_score(y_pred_LR, y)\n",
    "accuracy_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d97c8",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298bbb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5443037974683544"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN = KNeighborsClassifier().fit(X, y)\n",
    "y_pred_KNN = model_KNN.predict(X)\n",
    "\n",
    "accuracy_KNN = accuracy_score(y_pred_KNN, y)\n",
    "accuracy_KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8b31b",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4fb9ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7088607594936709"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVM = SVC().fit(X, y)\n",
    "y_pred_SVM = model_SVM.predict(X)\n",
    "\n",
    "accuracy_SVM = accuracy_score(y_pred_SVM, y)\n",
    "accuracy_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e086c6e",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy\n",
    "\n",
    "Understand the model accuracies better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194e0e8",
   "metadata": {},
   "source": [
    "### Best model\n",
    "\n",
    "Based on the results from the model building, SVM had the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed4dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "\n",
      "Logistic Regression:\t 1.0\n",
      "KNN:\t\t\t 0.5443037974683544\n",
      "SVM:\t\t\t 0.7088607594936709\n"
     ]
    }
   ],
   "source": [
    "print('Accuracies:')\n",
    "print('\\nLogistic Regression:\\t', accuracy_LR)\n",
    "print('KNN:\\t\\t\\t', accuracy_KNN)\n",
    "print('SVM:\\t\\t\\t', accuracy_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9f0fb",
   "metadata": {},
   "source": [
    "Perform cross validation to compare this to the other prediction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e9d4a6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.4660714285714286, 0.1541206954808802), 'KNN': (0.48035714285714287, 0.18148515709252358), 'SVM': (0.5321428571428571, 0.05101020306102036)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6977e07b",
   "metadata": {},
   "source": [
    "### Understand the differences\n",
    "\n",
    "View the value counts to better understand how the predictions and true values are distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c7f9f5",
   "metadata": {},
   "source": [
    "#### Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d55beae6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42\n",
       "1    23\n",
       "3    12\n",
       "2     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred_LR).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecbee57",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3da2233f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    65\n",
       "1    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred_SVM).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21880e",
   "metadata": {},
   "source": [
    "#### True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a7e903f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DX\n",
       "0    42\n",
       "1    23\n",
       "3    12\n",
       "2     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
