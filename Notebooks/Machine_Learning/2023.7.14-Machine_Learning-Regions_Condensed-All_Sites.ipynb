{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe86858",
   "metadata": {},
   "source": [
    "# Machine Learning with Condensed Region Data\n",
    "\n",
    "This notebook investigates the performance of machine learning models to recognize ADHD in subjects. \n",
    "The original dataset for this test consists of average signal intensities for regions of the brain as determined by the AAL atlas from the 7 training sites in the ADHD-200 Competition set. \n",
    "The dataset that will be used in this notebook has been adapted from the original to include only the regions that have the highest correlation to the target (diagnosis).\n",
    "\n",
    "This notebook runs four tests to evaluate the accuracy of multiple classification models.\n",
    "1. Multi-class diagnosis (uses all diagnosis types)\n",
    "1. Multi-class diagnosis (uses all diagnosis types) with normalized features\n",
    "2. Binary classification (if subject has ADHD or not)\n",
    "2. Binary classification (if subject has ADHD or not) with normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d8c21",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the imports that are required for this notebook to run properly\n",
    "\n",
    "- `os` to access the file\n",
    "\n",
    "- `pandas` to work with dataframes\n",
    "\n",
    "- `numpy` for linear algebra\n",
    "\n",
    "- `seaborn` for customizable plotting\n",
    "\n",
    "- `matplotlib.pyplot` for plotting\n",
    "\n",
    "\n",
    "- `train_test_split()` for splitting data into a training and testing set\n",
    "\n",
    "- `LogisticRegression` for a logistic regression machine learning model\n",
    "\n",
    "- `KNeighborsClassifier` for a KNN machine learning model\n",
    "\n",
    "- `SVC` for a SVM machine learning model\n",
    "\n",
    "- `LinearDiscriminantAnalysis` for a LDA machine learning model\n",
    "\n",
    "- `Voting Classifier` for ensemble methods\n",
    "\n",
    "\n",
    "- `accuracy_score()` to evaluate the accuracy of the model\n",
    "\n",
    "- `confusion_matrix` and `ConfusionMatrixDisplay` for viewing confusion matrices\n",
    "\n",
    "- `StratifiedKFold, cross_valscore()` for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d263165",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "logr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ens = VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm), ('lda',lda)])\n",
    "ensl = VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm)])\n",
    "\n",
    "models.append(('LR', logr))\n",
    "models.append(('KNN', knn))\n",
    "models.append(('SVM', svm))\n",
    "models.append(('LDA', lda))\n",
    "models.append(('Ensemble', ens))\n",
    "models.append(('Ensemble Less', ensl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86a398",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "There are several functions in this notebook to improve the code readability and reduce the length of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fc6b7",
   "metadata": {},
   "source": [
    "### get_base_filepath()\n",
    "\n",
    "Access the filepath for th ebase folder of the project. \n",
    "From here, any other asset of the project can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18789d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filepath():\n",
    "    '''\n",
    "    Access the filepath for the base folder of the project\n",
    "    \n",
    "    Input: None\n",
    "    \n",
    "    Output: The filepath to the root of the folder\n",
    "    '''\n",
    "    # Get current directory\n",
    "    os.path.abspath(os.curdir)\n",
    "\n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "    \n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "\n",
    "    # Set baseline filepath to the project folder directory\n",
    "    base_folder_filepath = os.path.abspath(os.curdir)\n",
    "    return base_folder_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca09b4b",
   "metadata": {},
   "source": [
    "### normalize()\n",
    "\n",
    "Normalizes a Series\n",
    "\n",
    "**Input:** A feature of type Series\n",
    "\n",
    "**Output:** The normalized feature of type Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(feature):\n",
    "    '''\n",
    "    This function normalizes a Series\n",
    "    \n",
    "    Input: A feature of type Series\n",
    "    \n",
    "    Output: The normalized feature of type Series\n",
    "    '''\n",
    "    return (feature - feature.mean())/feature.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ac0bd",
   "metadata": {},
   "source": [
    "### normalize_features()\n",
    "\n",
    "Normalizes all features in a given dataframe. This will normalize ALL features, so ensure that the inputted dataframe consists only of numeric values.\n",
    "\n",
    "**Input:** A dataframe to normalize\n",
    "\n",
    "**Output:** A normalized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df):\n",
    "    '''\n",
    "    This function normalizes all features in a dataframe\n",
    "    \n",
    "    Input: A pandas dataframe\n",
    "    \n",
    "    Output: The normalized dataframe\n",
    "    '''\n",
    "    for column in df.columns:\n",
    "        df[column] = normalize(df[column])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39105c",
   "metadata": {},
   "source": [
    "### get_statistics()\n",
    "\n",
    "Get the descriptive statistics for a list of values\n",
    "    \n",
    "**Input:** A list of accuracies\n",
    "    \n",
    "**Output:** The mean, std, max, and min for each model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(accuracy_list):\n",
    "    '''\n",
    "    Get the descriptive statistics for a list of values\n",
    "    \n",
    "    Input: A list of accuracies\n",
    "    \n",
    "    Output: The mean, std, max, and min for each model's accuracy\n",
    "    '''\n",
    "    # Create empty lists for descriptive statistics\n",
    "    means = []\n",
    "    stds = []\n",
    "    maxes = []\n",
    "    mins = []\n",
    "    \n",
    "    # Access the descriptive statistics for each list of accuracies\n",
    "    for accuracy in accuracy_list:\n",
    "        accuracy_np = np.array(accuracy)\n",
    "        means.append(accuracy_np.mean())\n",
    "        stds.append(accuracy_np.std())\n",
    "        maxes.append(accuracy_np.max())\n",
    "        mins.append(accuracy_np.min())\n",
    "        \n",
    "    # Create a list for the statistics\n",
    "    stats = [means, stds, maxes, mins]\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2d03b",
   "metadata": {},
   "source": [
    "### make_predictions()\n",
    "\n",
    "Fit a model using the training data, \n",
    "make predictions on a testing set, \n",
    "and get the accuracy of the model.\n",
    "\n",
    "Used in evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, X_trn, X_tst, y_trn, y_tst):\n",
    "    '''\n",
    "    Get the accuracy of a model\n",
    "    \n",
    "    Input:\n",
    "        - A model to use to make predictions\n",
    "        - Set of training features\n",
    "        - Set of testing features\n",
    "        - Set of training targets\n",
    "        - Set of testing targets\n",
    "        \n",
    "    Output: Accuracy of the model\n",
    "    '''\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model_fit = model.fit(X_trn, y_trn)\n",
    "    \n",
    "    # Make predictions on the testing features\n",
    "    y_pred = model_fit.predict(X_tst)\n",
    "    \n",
    "    # Compare the predictions to the true values\n",
    "    accuracy = accuracy_score(y_pred, y_tst)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return y_pred, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f640b6",
   "metadata": {},
   "source": [
    "### evaluate_models()\n",
    "\n",
    "Evaluate the performance of models on a set of features and targets.\n",
    "\n",
    "Uses make_predictions()\n",
    "\n",
    "Used in get_accuracies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y):\n",
    "    '''\n",
    "    Evaluate the performance of models on a set of features and targets.\n",
    "    \n",
    "    Input:\n",
    "        - Set of features\n",
    "        - Set of targets\n",
    "        \n",
    "    Output: Accuracy of three models (Logistic regression, KNN, SVM)\n",
    "    '''\n",
    "    # Separate the data into training and testing sets\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y)\n",
    "    \n",
    "    logr = LogisticRegression()\n",
    "    knn = KNeighborsClassifier()\n",
    "    svm = SVC()\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    ens = VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm), ('lda',lda)])\n",
    "    ensl = VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm)])\n",
    "    \n",
    "    # Evaluate the accuracies using each model\n",
    "    lr_pred, lr_acc = make_predictions(logr, X_trn, X_tst, y_trn, y_tst)\n",
    "    knn_pred, knn_acc = make_predictions(knn, X_trn, X_tst, y_trn, y_tst)\n",
    "    svm_pred, svm_acc = make_predictions(svm, X_trn, X_tst, y_trn, y_tst)\n",
    "    lda_pred, lda_acc = make_predictions(lda, X_trn, X_tst, y_trn, y_tst)\n",
    "    ens_pred, ens_acc = make_predictions(ens, X_trn, X_tst, y_trn, y_tst)\n",
    "    ensl_pred, ensl_acc = make_predictions(ensl, X_trn, X_tst, y_trn, y_tst)\n",
    "    \n",
    "    # Get the confusion matrices for each model\n",
    "    lr_cfm = confusion_matrix(lr_pred, y_tst)\n",
    "    knn_cfm = confusion_matrix(knn_pred, y_tst)\n",
    "    svm_cfm = confusion_matrix(svm_pred, y_tst)\n",
    "    lda_cfm = confusion_matrix(lda_pred, y_tst)\n",
    "    ens_cfm = confusion_matrix(ens_pred, y_tst)\n",
    "    ensl_cfm = confusion_matrix(ensl_pred, y_tst)\n",
    "    \n",
    "    # Return the accuracy in a list format\n",
    "    return [lr_acc, knn_acc, svm_acc, lda_acc, ens_acc, ensl_acc], [lr_cfm, knn_cfm, svm_cfm, lda_cfm, ens_cfm, ensl_cfm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cdc526",
   "metadata": {},
   "source": [
    "### get_accuracies()\n",
    "\n",
    "Get 100 accuracies for three models (Logistic regression, KNN, SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(X, y):\n",
    "    '''\n",
    "    Get 100 accuracies for three models (Logistic regression, KNN, SVM).\n",
    "    \n",
    "    Input:\n",
    "        - Set of features\n",
    "        - Set of targets\n",
    "        \n",
    "    Output: List of 100 accuracies for the three models\n",
    "    '''\n",
    "    # Create an empty list to store the accuracies for each model\n",
    "    lr_acc = []\n",
    "    knn_acc = []\n",
    "    svm_acc = []\n",
    "    lda_acc = []\n",
    "    ens_acc = []\n",
    "    ensl_acc = []\n",
    "    \n",
    "    lr_matrices = []\n",
    "    knn_matrices = []\n",
    "    svm_matrices = []\n",
    "    lda_matrices = []\n",
    "    ens_matrices = []\n",
    "    ensl_matrices = []\n",
    "    \n",
    "    # Run 100 iterations of evaluating the model\n",
    "    for i in range(100):\n",
    "        # Get the accuracy for this iteration\n",
    "        accuracies, cf_matrices = evaluate_models(X, y)\n",
    "        \n",
    "        # Add it to the corresponding model holder\n",
    "        lr_acc.append(accuracies[0])\n",
    "        knn_acc.append(accuracies[1])\n",
    "        svm_acc.append(accuracies[2])\n",
    "        lda_acc.append(accuracies[3])\n",
    "        ens_acc.append(accuracies[4])\n",
    "        ensl_acc.append(accuracies[5])\n",
    "                  \n",
    "        # Add the confusion matrix to the corresponding model holder\n",
    "        lr_matrices.append(cf_matrices[0])\n",
    "        knn_matrices.append(cf_matrices[1])\n",
    "        svm_matrices.append(cf_matrices[2])\n",
    "        lda_matrices.append(cf_matrices[3])\n",
    "        ens_matrices.append(cf_matrices[4])\n",
    "        ensl_matrices.append(cf_matrices[5])\n",
    "                   \n",
    "    # Return a list of all accuracies\n",
    "    return [lr_acc, knn_acc, svm_acc, lda_acc, ens_acc, ensl_acc], [lr_matrices, knn_matrices, svm_matrices, lda_matrices, ens_matrices, ensl_matrices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fbc3a",
   "metadata": {},
   "source": [
    "### get_training_accuracies()\n",
    "\n",
    "Get the accuracy for each model of the using the training data\n",
    "    \n",
    "**Input:** features and targets\n",
    "    \n",
    "**Output:** A Series of accuracies of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cba714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_accuracies(X_, y_):\n",
    "    '''\n",
    "    Get the accuracy for each model of the using the training data\n",
    "    \n",
    "    Input: features and targets\n",
    "    \n",
    "    Output: A Series of accuracies of each model\n",
    "    '''\n",
    "    # Split the data into the same training and testing as when in feature selection\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, random_state=1)\n",
    "    \n",
    "    # Create an empty dataframe to hold the model accuracies\n",
    "    accuracies = dict()\n",
    "    \n",
    "    # Get the accuracies for each of the models\n",
    "    for name, model in models:\n",
    "        preds, pred_accuracy = make_predictions(model, X_train, X_test, y_train, y_test)\n",
    "        accuracies[name] = pred_accuracy\n",
    "    \n",
    "    return pd.Series(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2ecdd",
   "metadata": {},
   "source": [
    "### perform_cross_validation()\n",
    "\n",
    "Use a stratified K-fold for cross validation for the three classification models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a789d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(X_train, y_train):\n",
    "    '''\n",
    "    Input: \n",
    "        - A dataframe containing the features use to build the model\n",
    "        - A Series of the true values associated with the feature list\n",
    "    \n",
    "    Output: Printed result for the mean and standard deviation of each model\n",
    "    '''\n",
    "    # Create an empty dictionary to store the results\n",
    "    results = dict()\n",
    "\n",
    "    # Loop through the models\n",
    "    for name, model in models:\n",
    "        # Create a Stratified K-fold for cross validation\n",
    "        kfold = StratifiedKFold(n_splits=10)\n",
    "        \n",
    "        # Apply cross validation using the current model\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        \n",
    "        # Add the mean and standard deviation to the dictionary\n",
    "        results[name] = (cv_results.mean(), cv_results.std())\n",
    "\n",
    "    # Print the results\n",
    "    print('Model\\t\\tCV Mean\\t\\tCV std')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45698a8a",
   "metadata": {},
   "source": [
    "### get_avg_cfm()\n",
    "\n",
    "Get the average confusion matrix for a list of 100 matrices\n",
    "    \n",
    "**Input:** a list of 100 confusion matrices\n",
    "    \n",
    "**Output:** the average confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_cfm(cfms):\n",
    "    '''\n",
    "    Get the average confusion matrix for a list of 100 matrices\n",
    "    \n",
    "    Input: a list of 100 confusion matrices\n",
    "    \n",
    "    Output: the average confusion matrix\n",
    "    '''\n",
    "    # Create an empty confusion matrix based on the size\n",
    "    if len(cfms[0]) == 2:\n",
    "        cfm = [[0,0],\n",
    "                [0,0]]\n",
    "    else:\n",
    "        cfm = [[0,0,0,0],\n",
    "               [0,0,0,0],\n",
    "               [0,0,0,0],\n",
    "               [0,0,0,0]]\n",
    "          \n",
    "            \n",
    "    # Sum up the values for each index in the confusion matrix\n",
    "    for matrix in cfms:\n",
    "        for row in range(len(matrix)):\n",
    "            for col in range(len(matrix[row])):\n",
    "                # If the row or column are out of bounds, skip it and move on\n",
    "                if (len(matrix)==3 and len(cfm)==4) and (col==3 or row==3):\n",
    "                    continue\n",
    "                    \n",
    "                # If the row or column is at diagnosis 2 and the matrix is the incorrect size, move on\n",
    "                elif (len(matrix)==3 and len(cfm)==4) and (col==2 or row==2):\n",
    "                    continue\n",
    "                    \n",
    "                # Otherwise, add the element to the sum matrix\n",
    "                cfm[row][col] += matrix[col][row]\n",
    "                \n",
    "                \n",
    "    # Divide by the number of values in the set\n",
    "    for row in range(len(cfm)):\n",
    "        for col in range(len(cfm[row])):\n",
    "            cfm[row][col] /=100       \n",
    "    \n",
    "    # Return the mean confusion matrix\n",
    "    return cfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798538ac",
   "metadata": {},
   "source": [
    "### get_model_cfms()\n",
    "\n",
    "Get the confusion matrix for each model; intended for use after 100-iteration train/test split\n",
    "    \n",
    "**Input:** A list of the confusion matrices for each model\n",
    "    \n",
    "**Output:** The average confusion matrix for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cfms(cfms):\n",
    "    '''\n",
    "    Get the confusion matrix for each model; intended for use after 100-iteration train/test split\n",
    "    \n",
    "    Input: A list of the confusion matrices for each model\n",
    "    \n",
    "    Output: The average confusion matrix for each model\n",
    "    '''\n",
    "    # Create an empty list to store the average confusion matrices in\n",
    "    model_cfms = []\n",
    "    \n",
    "    # Get the average cfm for each model type\n",
    "    for cfm_set in cfms:\n",
    "        model_cfms.append(get_avg_cfm(cfm_set))\n",
    "    \n",
    "    # Return the average confusion matrices for each model type\n",
    "    return model_cfms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd2528",
   "metadata": {},
   "source": [
    "### print_confusion_matrix()\n",
    "\n",
    "Print a confusion matrix\n",
    "\n",
    "**Input:**\n",
    "\n",
    "- Confusion matrix to print\n",
    "- A string to make a more clear title for the graph\n",
    "        \n",
    "**Ouput:** Display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(cmf, name):\n",
    "    '''\n",
    "    Print a confusion matrix\n",
    "    \n",
    "    Input:\n",
    "        - Confusion matrix to print\n",
    "        - A string to make a more clear title for the graph\n",
    "        \n",
    "    Ouput: Display the confusion matrix\n",
    "    '''\n",
    "    # Create matrix part of heatmape\n",
    "    sns.heatmap(cmf,\n",
    "            annot=True,\n",
    "        )\n",
    "    \n",
    "    # Make graph labels\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.title('Confusion Matrix for ' + name)\n",
    "        \n",
    "    # Display graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095b378",
   "metadata": {},
   "source": [
    "### print_model_cfms()\n",
    "\n",
    "Print all model confusion matrices \n",
    "    \n",
    "**Input:** A list of confusion matrices for each model\n",
    "    \n",
    "**Output:** Average confusion matrix for each model printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab35f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_cfms(cfms):\n",
    "    '''\n",
    "    Print all model confusion matrices \n",
    "    \n",
    "    Input: A list of confusion matrices for each model\n",
    "    \n",
    "    Output: Average confusion matrix for each model printed\n",
    "    '''\n",
    "    for i, (name, model) in enumerate(models):\n",
    "        plt.figure(figsize=(3,2))\n",
    "        print_confusion_matrix(get_model_cfms(cfms)[i], name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b69910",
   "metadata": {},
   "source": [
    "### print_training_cfm()\n",
    "\n",
    "Print the confusion matrix for the training data\n",
    "    \n",
    "**Input:** features and targets\n",
    "    \n",
    "**Output:** The 6 model's confusion matrices outputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_training_cfm(X_, y_):\n",
    "    '''\n",
    "    Print the confusion matrix for the training data\n",
    "    \n",
    "    Input: features and targets\n",
    "    \n",
    "    Output: The 6 model's confusion matrices outputted\n",
    "    '''\n",
    "    # Split the data into the same training and testing as when in feature selection\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X_, y_, random_state=1)\n",
    "    \n",
    "    classifiers = {\n",
    "        'Logisitic Regression': LogisticRegression(),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'LDA': LinearDiscriminantAnalysis(),\n",
    "        'Ensemble': VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm), ('lda',lda)]),\n",
    "        'Ensemble (less)':VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm)])\n",
    "    }\n",
    "\n",
    "    f, axes = plt.subplots(1, 6, figsize=(20, 5), sharey='row')\n",
    "        \n",
    "    for i, (key, classifier) in enumerate(classifiers.items()):\n",
    "        y_pred = classifier.fit(X_trn, y_trn).predict(X_tst)\n",
    "        cf_matrix = confusion_matrix(y_tst, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(cf_matrix)\n",
    "        disp.plot(ax=axes[i], xticks_rotation=45)\n",
    "        disp.ax_.set_title(key)\n",
    "        disp.im_.colorbar.remove()\n",
    "        disp.ax_.set_xlabel('')\n",
    "        if i!=0:\n",
    "            disp.ax_.set_ylabel('')\n",
    "\n",
    "    f.text(0.4, 0.1, 'Predicted label', ha='left')\n",
    "    plt.subplots_adjust(wspace=0.40, hspace=0.1)\n",
    "\n",
    "    f.colorbar(disp.im_, ax=axes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12b3b3",
   "metadata": {},
   "source": [
    "## Import File\n",
    "\n",
    "Locate the file using its filepath from the base folder and load the file as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62601446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder for the project\n",
    "base_folder_filepath = get_base_filepath()\n",
    "\n",
    "# Preprocessed data folder\n",
    "filepath = base_folder_filepath + '\\\\Data\\\\Preprocessed_data\\\\Condensed\\\\2023.7.14-Region_Condensed_Dataframe.csv'\n",
    "filepath_train = base_folder_filepath + '\\\\Data\\\\Preprocessed_data\\\\Condensed\\\\2023.7.20-Region_Condensed_Train_Dataframe.csv'\n",
    "\n",
    "# Dataframe from filepath\n",
    "df = pd.read_csv(filepath, index_col=0)\n",
    "df_train = pd.read_csv(filepath_train, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2269ad",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0944e96",
   "metadata": {},
   "source": [
    "# Multi-Class Classificaiton\n",
    "\n",
    "This section investigates how models perform when predicting the type of ADHD the subject has or if they are a control.\n",
    "\n",
    "This is accomplished by using the phenotypic data for the sites. The target will be the diagnosis which includes three types with each number corresponding to a type diagnosis for ADHD.\n",
    "\n",
    "    0 = TDC (Typically developing children)\n",
    "    1 = ADHD-Combined\n",
    "    2 = ADHD-Hyperactive/Impulsive\n",
    "    3 = ADHD-Inattentive\n",
    "    \n",
    "There will be three methods to make these predictions: \n",
    "\n",
    "- Current dataframe\n",
    "\n",
    "- Normalized dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd184e12",
   "metadata": {},
   "source": [
    "## Current Dataframe\n",
    "\n",
    "This model will use the current dataframe without any modifications to the features. \n",
    "This will act as a baseline to compare the models with changes to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b9a7a",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('DX', axis=1)\n",
    "y = df['DX']\n",
    "\n",
    "X_train = df_train.drop('DX', axis=1)\n",
    "y_train = df_train['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa29870",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ce758",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs, cfms = get_accuracies(X, y)\n",
    "\n",
    "accs_train, cfms_train = get_accuracies(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1910d8",
   "metadata": {},
   "source": [
    "#### View Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95da65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341a866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfms_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4990def",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_statistics(accs)\n",
    "results = pd.DataFrame(stats, \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_multiclass', 'KNN_multiclass', \n",
    "                                'SVM_multiclass', 'LDA_multiclass', \n",
    "                                'Ensemble_multiclass', 'Ensemble2_multiclass'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec871b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train = get_statistics(accs_train)\n",
    "results_train = pd.DataFrame(stats_train, \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_multiclass_train', 'KNN_multiclass_train', \n",
    "                                'SVM_multiclass_train', 'LDA_multiclass_train', \n",
    "                                'Ensemble_multiclass_train', 'Ensemble2_multiclass_train'])\n",
    "\n",
    "results_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968f706",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cd446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82394ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda081da",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "Logistic regression, SVM, and both ensemble were the most accurate methods in the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1149be0",
   "metadata": {},
   "source": [
    "## Normalized Dataframe\n",
    "\n",
    "This model will use a normalized version of the dataframe. \n",
    "This method will adjust the features to be normally distributed.\n",
    "\n",
    "This should reduce some of the bias that results from the different scales in the dataframe's features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cd6e3",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Make a copy of the original dataframe to ensure that it is preserved. \n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422435b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df.copy()\n",
    "df_train_norm = df_train.copy()\n",
    "\n",
    "X_norm = df_norm.drop('DX', axis=1)\n",
    "y_norm = df_norm['DX']\n",
    "\n",
    "X_train_norm = df_train_norm.drop('DX', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c988b3b",
   "metadata": {},
   "source": [
    "### Normalize columns\n",
    "\n",
    "Normalize the features and update the feature dataframe to use these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = normalize_features(X_norm)\n",
    "X_train_norm = normalize_features(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1a8e7",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d86aa",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea73705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accs_norm, cfms_norm = get_accuracies(X_norm, y)\n",
    "\n",
    "accs_train_norm, cfms_train_norm = get_accuracies(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade20ccd",
   "metadata": {},
   "source": [
    "#### View Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd833a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfms_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232595a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfms_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a403f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_norm = get_statistics(accs_norm)\n",
    "results_norm = pd.DataFrame(stats_norm, \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_multiclass_norm', 'KNN_multiclass_norm', \n",
    "                                'SVM_multiclass_norm', 'LDA_multiclass_norm',\n",
    "                                'Ensemble_multiclass_norm', 'Ensemble2_multiclass_norm'])\n",
    "\n",
    "results_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_train_norm = get_statistics(accs_train_norm)\n",
    "results_train_norm = pd.DataFrame(stats_train_norm, \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_multiclass_train_norm', 'KNN_train_multiclass_norm', \n",
    "                                'SVM_multiclass_train_norm', 'LDA_train_multiclass_norm',\n",
    "                                'Ensemble_multiclass_train_norm', 'Ensemble2_train_multiclass_norm'])\n",
    "\n",
    "results_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f6ed5",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8fbd3",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc266001",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_cross_validation(X_norm, y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_cross_validation(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf8076",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "SVM was the most accurate method in both the train/test split.\n",
    "This model was not more accurate than the previous test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827fa02",
   "metadata": {},
   "source": [
    "## Classification Conclusion\n",
    "\n",
    "The most accurate method for this classification type was logistic regression, SVM, and both ensemble methods on the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457d13d",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a79a5a",
   "metadata": {},
   "source": [
    "# Binary Classificaiton\n",
    "\n",
    "This section investigates how models perform when predicting whether a patient has ADHD or not. \n",
    "\n",
    "This is accomplished by converting the diagnosis to a binary value based on if their diagnosis is a control or has some type of ADHD. \n",
    "For this feature, 'True' signifies the subject has ADHD and 'False' signifies the subject is a control and does not have ADHD.\n",
    "\n",
    "Theoretically, this model should perform better than the multi-class classification since it is simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad0ded",
   "metadata": {},
   "source": [
    "## Base Binary Dataframe\n",
    "\n",
    "The binary dataframe is exactly the same as the multiclass dataframe except the diagnosis is binary. \n",
    "Any value for 'DX' greater than 0 for this column indicates that the subject has ADHD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = df.copy()\n",
    "df_binary_train = df_train.copy()\n",
    "\n",
    "df_binary['DX'].loc[df_binary['DX'] > 0] = 1\n",
    "df_binary_train['DX'].loc[df_binary_train['DX'] > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3f51b",
   "metadata": {},
   "source": [
    "## Binary Current Dataframe\n",
    "\n",
    "This model will use the current dataframe with the only modification being to the diagnosis column. \n",
    "Any value for 'DX' greater than 0 indicates that the patient has ADHD.\n",
    "\n",
    "This will act as a baseline to compare the binary models with other changes to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770f5e4",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_binary.drop('DX', axis=1)\n",
    "y_binary = df_binary['DX']\n",
    "\n",
    "X_binary_train = df_binary_train.drop('DX', axis=1)\n",
    "y_binary_train = df_binary_train['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d388afb",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295c86c",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_binary, cfm_binary = get_accuracies(X_binary, y_binary)\n",
    "\n",
    "accs_binary_train, cfm_binary_train = get_accuracies(X_binary_train, y_binary_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835bca1",
   "metadata": {},
   "source": [
    "#### View Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e108f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfm_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9ddb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfm_binary_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9b098",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_binary = get_statistics(accs_binary)\n",
    "results_binary = pd.DataFrame(stats_binary, \n",
    "                              index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                              columns=['LR_binary', 'KNN_binary', \n",
    "                                       'SVM_binary', 'LDA_binary', \n",
    "                                       'Ensemble_binary', 'Ensemble2_binary'])\n",
    "\n",
    "results_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_binary_train = get_statistics(accs_binary_train)\n",
    "results_binary_train = pd.DataFrame(stats_binary_train, \n",
    "                              index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                              columns=['LR_binary_train', 'KNN_binary_train', \n",
    "                                       'SVM_binary_train', 'LDA_binary_train', \n",
    "                                       'Ensemble_binary_train', 'Ensemble2_binary_train'])\n",
    "\n",
    "results_binary_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510297c",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cdfa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(X_binary, y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e73994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perform_cross_validation(X_binary_train, y_binary_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f441f08",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "\n",
    "LDA is the most accurate model for both train/test split. This method was more accurate than the previous tests in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f90a13",
   "metadata": {},
   "source": [
    "## Normalized Binary Dataframe\n",
    "\n",
    "This model will use a normalized version of the dataframe. \n",
    "This method will adjust the features to be normally distributed.\n",
    "\n",
    "This should reduce some of the bias that results from the different scales in the dataframe's features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66546c",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Make a copy of the original dataframe to ensure that it is preserved. \n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary_norm = df_binary.copy()\n",
    "df_binary_train_norm = df_binary_train.copy()\n",
    "\n",
    "X_binary_norm = df_binary_norm.drop('DX', axis=1)\n",
    "y_binary_norm = df_binary_norm['DX']\n",
    "\n",
    "X_binary_train_norm = df_binary_train_norm.drop('DX', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c347e",
   "metadata": {},
   "source": [
    "### Normalize columns\n",
    "\n",
    "Normalize the features and update the feature dataframe to use these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary_norm = normalize_features(X_binary_norm)\n",
    "X_binary_train_norm = normalize_features(X_binary_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b213d",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bc343",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_binary_norm, cfm_binary_norm = get_accuracies(X_binary_norm, y_binary)\n",
    "\n",
    "accs_binary_train_norm, cfm_binary_train_norm = get_accuracies(X_binary_train_norm, y_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe2300",
   "metadata": {},
   "source": [
    "#### View Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bd6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfm_binary_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea30a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_cfms(cfm_binary_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5cea5",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95910fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_binary_norm = get_statistics(accs_binary_norm)\n",
    "results_binary_norm = pd.DataFrame(stats_binary_norm, \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_binary_norm', 'KNN_binary_norm', \n",
    "                                'SVM_binary_norm', 'LDA_binary_norm', \n",
    "                                'Ensemble_binary_norm', 'Ensemble2_binary_norm'])\n",
    "\n",
    "results_binary_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_binary_train_norm = get_statistics(accs_binary_train_norm)\n",
    "results_binary_train_norm = pd.DataFrame(stats_binary_train_norm, \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_binary_train_norm', 'KNN_binary_train_norm', \n",
    "                                'SVM_binary_train_norm', 'LDA_binary_train_norm', \n",
    "                                'Ensemble_binary_train_norm', 'Ensemble2_binary_train_norm'])\n",
    "\n",
    "results_binary_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6159047",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_cross_validation(X_binary_norm, y_binary_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_cross_validation(X_binary_train_norm, y_binary_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b267c",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "The ensemble of all standard classification methods was the most accurate model.\n",
    "This model was note more accurate than the most accurate from the previous test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844423f",
   "metadata": {},
   "source": [
    "## Classification Conclusion\n",
    "\n",
    "The binary classification yielded more accurate predictions on average. \n",
    "The most accurate model from this notebook was LDA on the condensed dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4569b",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cfde7",
   "metadata": {},
   "source": [
    "# Complete Results\n",
    "\n",
    "Combine the accuracy from the multiclass and binary tests. \n",
    "\n",
    "Concatenate the two results to a single dataframe to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d330500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_complete = pd.concat([results, results_norm, results_binary, results_binary_norm], axis=1)\n",
    "results_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce8b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_complete_train = pd.concat([results_train, results_train_norm, \n",
    "                                    results_binary_train, results_binary_train_norm], axis=1)\n",
    "results_complete_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_complete.to_csv(base_folder_filepath + '\\\\Results\\\\2023.7.17-Regions_Condensed-Results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d9c86",
   "metadata": {},
   "source": [
    "### Evaluate Controlled train/test split\n",
    "\n",
    "Use the same random state as was used in feature selection to determine the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2839bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc_binary = get_training_accuracies(X_binary_train, y_binary_train)\n",
    "training_acc_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77072d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_training_cfm(X_binary_train, y_binary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc_binary_norm = get_training_accuracies(X_binary_train_norm, y_binary_train)\n",
    "training_acc_binary_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_training_cfm(X_binary_train_norm, y_binary_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = get_training_accuracies(X_train, y_train)\n",
    "training_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_training_cfm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc_norm= get_training_accuracies(X_train_norm, y_train)\n",
    "training_acc_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725713d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_training_cfm(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317810e",
   "metadata": {},
   "source": [
    "Combine results into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ['Binary', 'Binary Normalized', 'Multiclass', 'Multiclass Normalized']\n",
    "training_results = pd.concat([training_acc_binary, training_acc_binary_norm, \n",
    "                             training_acc, training_acc_norm], axis=1)\n",
    "\n",
    "training_results.columns = model_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cf685",
   "metadata": {},
   "source": [
    "Export results as .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results.to_csv(base_folder_filepath + '\\\\Results\\\\2023.7.24-Region_Condensed_Train-Results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
