{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe86858",
   "metadata": {},
   "source": [
    "# Machine Learning with Condensed Region Data\n",
    "\n",
    "This notebook investigates the performance of machine learning models to recognize ADHD in subjects. \n",
    "The original dataset for this test consists of average signal intensities for regions of the brain as determined by the AAL atlas from the 7 training sites in the ADHD-200 Competition set. \n",
    "The dataset that will be used in this notebook has been adapted from the original to include only the regions that have the highest correlation to the target (diagnosis).\n",
    "\n",
    "This notebook runs four tests to evaluate the accuracy of multiple classification models.\n",
    "1. Multi-class diagnosis (uses all diagnosis types)\n",
    "1. Multi-class diagnosis (uses all diagnosis types) with normalized features\n",
    "2. Binary classification (if subject has ADHD or not)\n",
    "2. Binary classification (if subject has ADHD or not) with normalized features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d8c21",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the imports that are required for this notebook to run properly\n",
    "\n",
    "- `os` to access the file\n",
    "\n",
    "- `pandas` to work with dataframes\n",
    "\n",
    "- `numpy` for linear algebra\n",
    "\n",
    "\n",
    "- `train_test_split()` for splitting data into a training and testing set\n",
    "\n",
    "- `LogisticRegression` for a logistic regression machine learning model\n",
    "\n",
    "- `KNeighborsClassifier` for a KNN machine learning model\n",
    "\n",
    "- `SVC` for a SVM machine learning model\n",
    "\n",
    "- `LinearDiscriminantAnalysis` for a LDA machine learning model\n",
    "\n",
    "\n",
    "- `accuracy_score()` to evaluate the accuracy of the model\n",
    "\n",
    "- `StratifiedKFold, cross_valscore()` for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ba9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d263165",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "logr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ens = VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm), ('lda',lda)])\n",
    "\n",
    "models.append(('LR', logr))\n",
    "models.append(('KNN', knn))\n",
    "models.append(('SVM', svm))\n",
    "models.append(('LDA', lda))\n",
    "models.append(('Ensemble', ens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86a398",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "There are several functions in this notebook to improve the code readability and reduce the length of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fc6b7",
   "metadata": {},
   "source": [
    "### get_base_filepath()\n",
    "\n",
    "Access the filepath for th ebase folder of the project. \n",
    "From here, any other asset of the project can be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18789d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_filepath():\n",
    "    '''\n",
    "    Access the filepath for the base folder of the project\n",
    "    \n",
    "    Input: None\n",
    "    \n",
    "    Output: The filepath to the root of the folder\n",
    "    '''\n",
    "    # Get current directory\n",
    "    os.path.abspath(os.curdir)\n",
    "\n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "    \n",
    "    # Go up a directory level\n",
    "    os.chdir('..')\n",
    "\n",
    "    # Set baseline filepath to the project folder directory\n",
    "    base_folder_filepath = os.path.abspath(os.curdir)\n",
    "    return base_folder_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca09b4b",
   "metadata": {},
   "source": [
    "### normalize()\n",
    "\n",
    "Normalizes a Series\n",
    "\n",
    "**Input:** A feature of type Series\n",
    "\n",
    "**Output:** The normalized feature of type Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e0d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(feature):\n",
    "    '''\n",
    "    This function normalizes a Series\n",
    "    \n",
    "    Input: A feature of type Series\n",
    "    \n",
    "    Output: The normalized feature of type Series\n",
    "    '''\n",
    "    return (feature - feature.mean())/feature.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ac0bd",
   "metadata": {},
   "source": [
    "### normalize_features()\n",
    "\n",
    "Normalizes all features in a given dataframe. This will normalize ALL features, so ensure that the inputted dataframe consists only of numeric values.\n",
    "\n",
    "**Input:** A dataframe to normalize\n",
    "\n",
    "**Output:** A normalized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e02eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df):\n",
    "    '''\n",
    "    This function normalizes all features in a dataframe\n",
    "    \n",
    "    Input: A pandas dataframe\n",
    "    \n",
    "    Output: The normalized dataframe\n",
    "    '''\n",
    "    for column in df.columns:\n",
    "        df[column] = normalize(df[column])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2d03b",
   "metadata": {},
   "source": [
    "### make_predictions()\n",
    "\n",
    "Fit a model using the training data, \n",
    "make predictions on a testing set, \n",
    "and get the accuracy of the model.\n",
    "\n",
    "Used in evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b7aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, X_trn, X_tst, y_trn, y_tst):\n",
    "    '''\n",
    "    Get the accuracy of a model\n",
    "    \n",
    "    Input:\n",
    "        - A model to use to make predictions\n",
    "        - Set of training features\n",
    "        - Set of testing features\n",
    "        - Set of training targets\n",
    "        - Set of testing targets\n",
    "        \n",
    "    Output: Accuracy of the model\n",
    "    '''\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model_fit = model.fit(X_trn, y_trn)\n",
    "    \n",
    "    # Make predictions on the testing features\n",
    "    y_pred = model_fit.predict(X_tst)\n",
    "    \n",
    "    # Compare the predictions to the true values\n",
    "    accuracy = accuracy_score(y_pred, y_tst)\n",
    "    \n",
    "    # Return the accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f640b6",
   "metadata": {},
   "source": [
    "### evaluate_models()\n",
    "\n",
    "Evaluate the performance of models on a set of features and targets.\n",
    "\n",
    "Uses make_predictions()\n",
    "\n",
    "Used in get_accuracies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fea0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X, y):\n",
    "    '''\n",
    "    Evaluate the performance of models on a set of features and targets.\n",
    "    \n",
    "    Input:\n",
    "        - Set of features\n",
    "        - Set of targets\n",
    "        \n",
    "    Output: Accuracy of three models (Logistic regression, KNN, SVM)\n",
    "    '''\n",
    "    # Separate the data into training and testing sets\n",
    "    X_trn, X_tst, y_trn, y_tst = train_test_split(X, y)\n",
    "    \n",
    "    logr = LogisticRegression()\n",
    "    knn = KNeighborsClassifier()\n",
    "    svm = SVC()\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    ens = VotingClassifier([('logr',logr), ('knn',knn), ('svm',svm), ('lda',lda)])\n",
    "    \n",
    "    # Evaluate the accuracies using each model\n",
    "    lr_acc = make_predictions(logr, X_trn, X_tst, y_trn, y_tst)\n",
    "    knn_acc = make_predictions(knn, X_trn, X_tst, y_trn, y_tst)\n",
    "    svm_acc = make_predictions(svm, X_trn, X_tst, y_trn, y_tst)\n",
    "    lda_acc = make_predictions(lda, X_trn, X_tst, y_trn, y_tst)\n",
    "    ens_acc = make_predictions(ens, X_trn, X_tst, y_trn, y_tst)\n",
    "    \n",
    "    # Return the accuracy in a list format\n",
    "    return [lr_acc, knn_acc, svm_acc, lda_acc, ens_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cdc526",
   "metadata": {},
   "source": [
    "### get_accuracies()\n",
    "\n",
    "Get 100 accuracies for three models (Logistic regression, KNN, SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cc43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(X, y):\n",
    "    '''\n",
    "    Get 100 accuracies for three models (Logistic regression, KNN, SVM).\n",
    "    \n",
    "    Input:\n",
    "        - Set of features\n",
    "        - Set of targets\n",
    "        \n",
    "    Output: List of 100 accuracies for the three models\n",
    "    '''\n",
    "    # Create an empty list to store the accuracies for each model\n",
    "    lr_acc = []\n",
    "    knn_acc = []\n",
    "    svm_acc = []\n",
    "    lda_acc = []\n",
    "    ens_acc = []\n",
    "    \n",
    "    # Run 100 iterations of evaluating the model\n",
    "    for i in range(100):\n",
    "        # Get the accuracy for this iteration\n",
    "        accuracies = evaluate_models(X, y)\n",
    "        \n",
    "        # Add it to the corresponding model holder\n",
    "        lr_acc.append(accuracies[0])\n",
    "        knn_acc.append(accuracies[1])\n",
    "        svm_acc.append(accuracies[2])\n",
    "        lda_acc.append(accuracies[3])\n",
    "        ens_acc.append(accuracies[4])\n",
    "        \n",
    "    # Return a list of all accuracies\n",
    "    return [lr_acc, knn_acc, svm_acc, lda_acc, ens_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2ecdd",
   "metadata": {},
   "source": [
    "### perform_cross_validation()\n",
    "\n",
    "Use a stratified K-fold for cross validation for the three classification models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a789d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(X_train, y_train):\n",
    "    '''\n",
    "    Input: \n",
    "        - A dataframe containing the features use to build the model\n",
    "        - A Series of the true values associated with the feature list\n",
    "    \n",
    "    Output: Printed result for the mean and standard deviation of each model\n",
    "    '''\n",
    "    # Create an empty dictionary to store the results\n",
    "    results = dict()\n",
    "\n",
    "    # Loop through the models\n",
    "    for name, model in models:\n",
    "        # Create a Stratified K-fold for cross validation\n",
    "        kfold = StratifiedKFold(n_splits=10)\n",
    "        \n",
    "        # Apply cross validation using the current model\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        \n",
    "        # Add the mean and standard deviation to the dictionary\n",
    "        results[name] = (cv_results.mean(), cv_results.std())\n",
    "\n",
    "    # Print the results\n",
    "    print('Model\\t\\tCV Mean\\t\\tCV std')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12b3b3",
   "metadata": {},
   "source": [
    "## Import File\n",
    "\n",
    "Locate the file using its filepath from the base folder and load the file as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62601446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The folder for the project\n",
    "base_folder_filepath = get_base_filepath()\n",
    "\n",
    "# Preprocessed data folder\n",
    "filepath = base_folder_filepath + '\\\\Data\\\\Preprocessed_data\\\\2023.7.14-Region_Condensed_Dataframe.csv'\n",
    "\n",
    "# Dataframe from filepath\n",
    "df = pd.read_csv(filepath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2269ad",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0944e96",
   "metadata": {},
   "source": [
    "# Multi-Class Classificaiton\n",
    "\n",
    "This section investigates how models perform when predicting the type of ADHD the subject has or if they are a control.\n",
    "\n",
    "This is accomplished by using the phenotypic data for the sites. The target will be the diagnosis which includes three types with each number corresponding to a type diagnosis for ADHD.\n",
    "\n",
    "    0 = TDC (Typically developing children)\n",
    "    1 = ADHD-Combined\n",
    "    2 = ADHD-Hyperactive/Impulsive\n",
    "    3 = ADHD-Inattentive\n",
    "    \n",
    "There will be three methods to make these predictions: \n",
    "\n",
    "- Current dataframe\n",
    "\n",
    "- Normalized dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd184e12",
   "metadata": {},
   "source": [
    "## Current Dataframe\n",
    "\n",
    "This model will use the current dataframe without any modifications to the features. \n",
    "This will act as a baseline to compare the models with changes to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b9a7a",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd1a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('DX', axis=1)\n",
    "y = df['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa29870",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ce758",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d9052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = get_accuracies(X, y)\n",
    "accuracies = np.asarray(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4990def",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85b5c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [accuracies[0].mean(), accuracies[1].mean(), accuracies[2].mean(), accuracies[3].mean(), accuracies[4].mean()]\n",
    "stds  = [accuracies[0].std(),  accuracies[1].std(),  accuracies[2].std(),  accuracies[3].std(),  accuracies[4].std()]\n",
    "maxes = [accuracies[0].max(),  accuracies[1].max(),  accuracies[2].max(),  accuracies[3].max(),  accuracies[4].max()]\n",
    "mins  = [accuracies[0].min(),  accuracies[1].min(),  accuracies[2].min(),  accuracies[3].min(),  accuracies[4].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7836f2",
   "metadata": {},
   "source": [
    "Format the descriptive statistics as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd2bee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_multiclass</th>\n",
       "      <th>KNN_multiclass</th>\n",
       "      <th>SVM_multiclass</th>\n",
       "      <th>LDA_multiclass</th>\n",
       "      <th>Ensemble_multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.630127</td>\n",
       "      <td>0.582739</td>\n",
       "      <td>0.629936</td>\n",
       "      <td>0.610764</td>\n",
       "      <td>0.630127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.035694</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.035572</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.035694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.503185</td>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.560510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LR_multiclass  KNN_multiclass  SVM_multiclass  LDA_multiclass   \n",
       "Mean       0.630127        0.582739        0.629936        0.610764  \\\n",
       "STD        0.035694        0.032183        0.035572        0.036865   \n",
       "Max        0.707006        0.675159        0.707006        0.694268   \n",
       "Min        0.560510        0.503185        0.560510        0.535032   \n",
       "\n",
       "      Ensemble_multiclass  \n",
       "Mean             0.630127  \n",
       "STD              0.035694  \n",
       "Max              0.707006  \n",
       "Min              0.560510  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame([means, stds, maxes, mins], \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_multiclass', 'KNN_multiclass', \n",
    "                                'SVM_multiclass', 'LDA_multiclass', 'Ensemble_multiclass'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968f706",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48cd446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.6290066564260113, 0.008930862894101646), 'KNN': (0.5608038914490528, 0.07719861970677068), 'SVM': (0.6274193548387097, 0.009146666829568337), 'LDA': (0.6114439324116744, 0.03051346941825479), 'Ensemble': (0.6290066564260113, 0.008930862894101646)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda081da",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "Logistic regression and SVM were the most accurate method in the train/test split, and logistic regression was the most accurate method for cross validation. \n",
    "The train/test split and cross-validation had similar results.\n",
    "\n",
    "Logistic regression and SVM are close to the average from using all features, but not higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1149be0",
   "metadata": {},
   "source": [
    "## Normalized Dataframe\n",
    "\n",
    "This model will use a normalized version of the dataframe. \n",
    "This method will adjust the features to be normally distributed.\n",
    "\n",
    "This should reduce some of the bias that results from the different scales in the dataframe's features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cd6e3",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Make a copy of the original dataframe to ensure that it is preserved. \n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422435b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df.copy()\n",
    "\n",
    "X_norm = df_norm.drop('DX', axis=1)\n",
    "y_norm = df_norm['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c988b3b",
   "metadata": {},
   "source": [
    "### Normalize columns\n",
    "\n",
    "Normalize the features and update the feature dataframe to use these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f34b6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = normalize_features(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1a8e7",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d86aa",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea73705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "accs_norm = get_accuracies(X_norm, y_norm)\n",
    "accuracies_norm = np.asarray(accs_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996f6ed5",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4dc9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_norm = [accuracies_norm[0].mean(), accuracies_norm[1].mean(), accuracies_norm[2].mean(), accuracies_norm[3].mean(), accuracies_norm[4].mean()]\n",
    "stds_norm  = [accuracies_norm[0].std(),  accuracies_norm[1].std(),  accuracies_norm[2].std(),  accuracies_norm[3].std(),  accuracies_norm[4].std()]\n",
    "maxes_norm = [accuracies_norm[0].max(),  accuracies_norm[1].max(),  accuracies_norm[2].max(),  accuracies_norm[3].max(),  accuracies_norm[4].max()]\n",
    "mins_norm  = [accuracies_norm[0].min(),  accuracies_norm[1].min(),  accuracies_norm[2].min(),  accuracies_norm[3].min(),  accuracies_norm[4].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0b1c2",
   "metadata": {},
   "source": [
    "Format the descriptive statistics as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02e8a57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_multiclass_norm</th>\n",
       "      <th>KNN_multiclass_norm</th>\n",
       "      <th>SVM_multiclass_norm</th>\n",
       "      <th>LDA_multiclass_norm</th>\n",
       "      <th>Ensemble_multiclass_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.611847</td>\n",
       "      <td>0.589936</td>\n",
       "      <td>0.630255</td>\n",
       "      <td>0.612166</td>\n",
       "      <td>0.629236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.034780</td>\n",
       "      <td>0.034310</td>\n",
       "      <td>0.032357</td>\n",
       "      <td>0.033376</td>\n",
       "      <td>0.033320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.700637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.541401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LR_multiclass_norm  KNN_multiclass_norm  SVM_multiclass_norm   \n",
       "Mean            0.611847             0.589936             0.630255  \\\n",
       "STD             0.034780             0.034310             0.032357   \n",
       "Max             0.707006             0.675159             0.707006   \n",
       "Min             0.522293             0.515924             0.541401   \n",
       "\n",
       "      LDA_multiclass_norm  Ensemble_multiclass_norm  \n",
       "Mean             0.612166                  0.629236  \n",
       "STD              0.033376                  0.033320  \n",
       "Max              0.694268                  0.700637  \n",
       "Min              0.522293                  0.541401  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_norm = pd.DataFrame([means_norm, stds_norm, maxes_norm, mins_norm], \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_multiclass_norm', 'KNN_multiclass_norm', \n",
    "                                'SVM_multiclass_norm', 'LDA_multiclass_norm',\n",
    "                                'Ensemble_multiclass_norm'])\n",
    "\n",
    "results_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8fbd3",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc266001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\taylo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.5988223246287763, 0.05283969797865226), 'KNN': (0.5767025089605735, 0.06679154940398133), 'SVM': (0.6274193548387097, 0.009146666829568337), 'LDA': (0.6114439324116744, 0.03051346941825479), 'Ensemble': (0.6273937532002049, 0.01594560808460879)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X_norm, y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf8076",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "SVM was the most accurate method in both the train/test split and cross-validation.\n",
    "The train/test split and cross-validation had similar results.\n",
    "\n",
    "SVM is the only model from this test that is better than the previous test using the condensed features. \n",
    "\n",
    "SVM is also higher than the average from using all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827fa02",
   "metadata": {},
   "source": [
    "## Classification Conclusion\n",
    "\n",
    "The most accurate method for this classification method was SVM on the normalized dataframe.\n",
    "\n",
    "This method scored with higher accuracy than the same dataframe with all region means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457d13d",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a79a5a",
   "metadata": {},
   "source": [
    "# Binary Classificaiton\n",
    "\n",
    "This section investigates how models perform when predicting whether a patient has ADHD or not. \n",
    "\n",
    "This is accomplished by converting the diagnosis to a binary value based on if their diagnosis is a control or has some type of ADHD. \n",
    "For this feature, 'True' signifies the subject has ADHD and 'False' signifies the subject is a control and does not have ADHD.\n",
    "\n",
    "Theoretically, this model should perform better than the multi-class classification since it is simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad0ded",
   "metadata": {},
   "source": [
    "## Base Binary Dataframe\n",
    "\n",
    "The binary dataframe is exactly the same as the multiclass dataframe except the diagnosis is binary. \n",
    "Any value for 'DX' greater than 0 for this column indicates that the subject has ADHD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aed97eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taylo\\AppData\\Local\\Temp\\ipykernel_14888\\1547292122.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_binary['DX'].loc[df_binary['DX'] > 0] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_4001</th>\n",
       "      <th>Mean_4002</th>\n",
       "      <th>Mean_4011</th>\n",
       "      <th>Mean_4021</th>\n",
       "      <th>Mean_4102</th>\n",
       "      <th>Mean_5011</th>\n",
       "      <th>Mean_5012</th>\n",
       "      <th>Mean_6002</th>\n",
       "      <th>Mean_6221</th>\n",
       "      <th>Mean_6302</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_8122</th>\n",
       "      <th>Mean_8201</th>\n",
       "      <th>Mean_8211</th>\n",
       "      <th>Mean_9041</th>\n",
       "      <th>Mean_9071</th>\n",
       "      <th>Mean_9072</th>\n",
       "      <th>Mean_9150</th>\n",
       "      <th>Mean_9160</th>\n",
       "      <th>Mean_9170</th>\n",
       "      <th>DX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>-0.001229</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.003605</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>-0.000998</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>-0.005823</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>-0.004338</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.000929</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-0.003816</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>-0.002847</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>-0.001799</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>-0.001324</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>-0.002685</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.008435</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean_4001  Mean_4002  Mean_4011  Mean_4021  Mean_4102  Mean_5011   \n",
       "10001   0.003551   0.001368   0.001056  -0.001229  -0.000540  -0.003605  \\\n",
       "10002  -0.005823  -0.002241   0.001463  -0.004338   0.002755  -0.000571   \n",
       "10003   0.005478   0.002208   0.004277   0.000060  -0.003816   0.004641   \n",
       "10004  -0.002847  -0.001133  -0.000901   0.002363   0.000122   0.001875   \n",
       "10005   0.008340   0.007814  -0.000297  -0.005694  -0.001799  -0.002059   \n",
       "\n",
       "       Mean_5012  Mean_6002  Mean_6221  Mean_6302  ...  Mean_8122  Mean_8201   \n",
       "10001  -0.002618   0.000094   0.000855  -0.001402  ...   0.001068   0.002020  \\\n",
       "10002   0.000071  -0.001889  -0.000175  -0.000058  ...   0.001865   0.002288   \n",
       "10003   0.004576   0.001011  -0.001067   0.001231  ...   0.009668   0.000621   \n",
       "10004   0.002724   0.000547   0.001156   0.002530  ...  -0.001246   0.002599   \n",
       "10005  -0.001324   0.004112   0.004462  -0.000078  ...  -0.001998  -0.002685   \n",
       "\n",
       "       Mean_8211  Mean_9041  Mean_9071  Mean_9072  Mean_9150  Mean_9160   \n",
       "10001   0.003910  -0.000998  -0.001536  -0.001464   0.002460   0.001810  \\\n",
       "10002   0.001013  -0.000929  -0.001079  -0.000776  -0.000629  -0.000025   \n",
       "10003  -0.003601   0.003619  -0.002535  -0.003021   0.001620  -0.000059   \n",
       "10004   0.001361   0.003420   0.000037  -0.000959   0.000302  -0.000304   \n",
       "10005  -0.001065  -0.008435   0.002573   0.000648  -0.000393  -0.003564   \n",
       "\n",
       "       Mean_9170  DX  \n",
       "10001  -0.000823   1  \n",
       "10002   0.001806   1  \n",
       "10003  -0.007794   0  \n",
       "10004  -0.000530   0  \n",
       "10005  -0.001598   1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary = df.copy()\n",
    "\n",
    "df_binary['DX'].loc[df_binary['DX'] > 0] = 1\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3f51b",
   "metadata": {},
   "source": [
    "## Binary Current Dataframe\n",
    "\n",
    "This model will use the current dataframe with the only modification being to the diagnosis column. \n",
    "Any value for 'DX' greater than 0 indicates that the patient has ADHD.\n",
    "\n",
    "This will act as a baseline to compare the binary models with other changes to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770f5e4",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab8b43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary = df_binary.drop('DX', axis=1)\n",
    "y_binary = df_binary['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d388afb",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295c86c",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a65382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_binary = get_accuracies(X_binary, y_binary)\n",
    "accuracies_binary = np.asarray(accs_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9b098",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ff7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_binary = [accuracies_binary[0].mean(), accuracies_binary[1].mean(), accuracies_binary[2].mean(), accuracies_binary[3].mean(), accuracies_binary[4].mean()]\n",
    "stds_binary  = [accuracies_binary[0].std(),  accuracies_binary[1].std(),  accuracies_binary[2].std(),  accuracies_binary[3].std(),  accuracies_binary[4].std()]\n",
    "maxes_binary = [accuracies_binary[0].max(),  accuracies_binary[1].max(),  accuracies_binary[2].max(),  accuracies_binary[3].max(),  accuracies_binary[4].max()]\n",
    "mins_binary  = [accuracies_binary[0].min(),  accuracies_binary[1].min(),  accuracies_binary[2].min(),  accuracies_binary[3].min(),  accuracies_binary[4].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253a334",
   "metadata": {},
   "source": [
    "Format the descriptive statistics as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e6af23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_binary</th>\n",
       "      <th>KNN_binary</th>\n",
       "      <th>SVM_binary</th>\n",
       "      <th>LDA_binary</th>\n",
       "      <th>Ensemble_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.627389</td>\n",
       "      <td>0.631274</td>\n",
       "      <td>0.627006</td>\n",
       "      <td>0.627707</td>\n",
       "      <td>0.627516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.035640</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.036115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>0.713376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.554140</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.515924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LR_binary  KNN_binary  SVM_binary  LDA_binary  Ensemble_binary\n",
       "Mean   0.627389    0.631274    0.627006    0.627707         0.627516\n",
       "STD    0.035640    0.033823    0.034599    0.035628         0.036115\n",
       "Max    0.713376    0.700637    0.700637    0.745223         0.713376\n",
       "Min    0.522293    0.554140    0.515924    0.541401         0.515924"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_binary = pd.DataFrame([means_binary, stds_binary, maxes_binary, mins_binary], \n",
    "                              index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                              columns=['LR_binary', 'KNN_binary', \n",
    "                                       'SVM_binary', 'LDA_binary', 'Ensemble_binary'])\n",
    "\n",
    "results_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510297c",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c08cdfa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.6289810547875063, 0.006873265171196576), 'KNN': (0.6054275473630313, 0.10340918547205324), 'SVM': (0.5940604198668714, 0.05383047536239013), 'LDA': (0.6291602662570405, 0.060572551530569514), 'Ensemble': (0.6242191500256016, 0.019907739280273323)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X_binary, y_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f441f08",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "LDA is the most accurate model for both train/test split and cross-validation with all models very close.\n",
    "\n",
    "None of these models are higher than the SVM model on the normalized dataframe from earlier in the notebook.\n",
    "\n",
    "KNN and LDA performed better than the binary classification from the average from using all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f90a13",
   "metadata": {},
   "source": [
    "## Normalized Binary Dataframe\n",
    "\n",
    "This model will use a normalized version of the dataframe. \n",
    "This method will adjust the features to be normally distributed.\n",
    "\n",
    "This should reduce some of the bias that results from the different scales in the dataframe's features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66546c",
   "metadata": {},
   "source": [
    "### Separate data\n",
    "\n",
    "Make a copy of the original dataframe to ensure that it is preserved. \n",
    "Split the data into features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb60d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary_norm = df_binary.copy()\n",
    "\n",
    "X_binary_norm = df_binary_norm.drop('DX', axis=1)\n",
    "y_binary_norm = df_binary_norm['DX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c347e",
   "metadata": {},
   "source": [
    "### Normalize columns\n",
    "\n",
    "Normalize the features and update the feature dataframe to use these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccde23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binary_norm = normalize_features(X_binary_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b213d",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy\n",
    "\n",
    "Determine the accuracy of using this dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bc343",
   "metadata": {},
   "source": [
    "#### 100-iteration Train/Test Split\n",
    "\n",
    "Do 100-iterations of train/test splits using this dataframe. \n",
    "Generate 100 accuracies for the four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b04feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_binary_norm = get_accuracies(X_binary_norm, y_binary_norm)\n",
    "accuracies_binary_norm = np.asarray(accs_binary_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5cea5",
   "metadata": {},
   "source": [
    "Extract descriptive statistics from the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15830616",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_binary_norm = [accuracies_binary_norm[0].mean(), accuracies_binary_norm[1].mean(), accuracies_binary_norm[2].mean(), accuracies_binary_norm[3].mean(), accuracies_binary_norm[4].mean()]\n",
    "stds_binary_norm  = [accuracies_binary_norm[0].std(),  accuracies_binary_norm[1].std(),  accuracies_binary_norm[2].std(),  accuracies_binary_norm[3].std(),  accuracies_binary_norm[4].std()]\n",
    "maxes_binary_norm = [accuracies_binary_norm[0].max(),  accuracies_binary_norm[1].max(),  accuracies_binary_norm[2].max(),  accuracies_binary_norm[3].max(),  accuracies_binary_norm[4].max()]\n",
    "mins_binary_norm  = [accuracies_binary_norm[0].min(),  accuracies_binary_norm[1].min(),  accuracies_binary_norm[2].min(),  accuracies_binary_norm[3].min(),  accuracies_binary_norm[4].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cea3d",
   "metadata": {},
   "source": [
    "Format the descriptive statistics as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0771062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_binary_norm</th>\n",
       "      <th>KNN_binary_norm</th>\n",
       "      <th>SVM_binary_norm</th>\n",
       "      <th>LDA_binary_norm</th>\n",
       "      <th>Ensemble_binary_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.632038</td>\n",
       "      <td>0.620382</td>\n",
       "      <td>0.631019</td>\n",
       "      <td>0.631401</td>\n",
       "      <td>0.635605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.033702</td>\n",
       "      <td>0.036523</td>\n",
       "      <td>0.033124</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>0.033502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.687898</td>\n",
       "      <td>0.732484</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.528662</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.535032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LR_binary_norm  KNN_binary_norm  SVM_binary_norm  LDA_binary_norm   \n",
       "Mean        0.632038         0.620382         0.631019         0.631401  \\\n",
       "STD         0.033702         0.036523         0.033124         0.034848   \n",
       "Max         0.687898         0.732484         0.694268         0.694268   \n",
       "Min         0.535032         0.528662         0.522293         0.522293   \n",
       "\n",
       "      Ensemble_binary_norm  \n",
       "Mean              0.635605  \n",
       "STD               0.033502  \n",
       "Max               0.707006  \n",
       "Min               0.535032  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_binary_norm = pd.DataFrame([means_binary_norm, stds_binary_norm, maxes_binary_norm, mins_binary_norm], \n",
    "                       index=['Mean', 'STD', 'Max', 'Min'], \n",
    "                       columns=['LR_binary_norm', 'KNN_binary_norm', \n",
    "                                'SVM_binary_norm', 'LDA_binary_norm', \n",
    "                                'Ensemble_binary_norm'])\n",
    "\n",
    "results_binary_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6159047",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Perform cross validation on this dataset with the four models from before. This is done to compare the results to the train-test split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "830f12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\tCV Mean\t\tCV std\n",
      "{'LR': (0.6292114695340503, 0.07786838833775525), 'KNN': (0.6182795698924731, 0.10282530870140304), 'SVM': (0.5877368151561699, 0.055485555272934674), 'LDA': (0.6291602662570405, 0.060572551530569514), 'Ensemble': (0.622657450076805, 0.04156943807040537)}\n"
     ]
    }
   ],
   "source": [
    "perform_cross_validation(X_binary_norm, y_binary_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b267c",
   "metadata": {},
   "source": [
    "### Method Conclusion\n",
    "\n",
    "LDA is the most accurate model for both train/test split and cross-validation with all models very close.\n",
    "\n",
    "None of these models are higher than the SVM model on the normalized dataframe from earlier in the notebook or the LDA from the baseline binary models.\n",
    "\n",
    "Logistic regression, SVM and LDA performed better than the binary classification from the average from using all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844423f",
   "metadata": {},
   "source": [
    "## Classification Conclusion\n",
    "\n",
    "The binary classification yielded more accurate predictions on average. \n",
    "However, the most accurate model from this notebook was SVM on the normalized features.\n",
    "\n",
    "Using SVM on a normalized multi-class dataframe resulted in the most accurate model. \n",
    "Using LDA on a unchanged dataframe resulted in the most accurate binary model. Both of these outpreformed their respective classification method on the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4569b",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cfde7",
   "metadata": {},
   "source": [
    "# Complete Results\n",
    "\n",
    "Combine the accuracy from the multiclass and binary tests. \n",
    "\n",
    "Concatenate the two results to a single dataframe to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d330500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_multiclass</th>\n",
       "      <th>KNN_multiclass</th>\n",
       "      <th>SVM_multiclass</th>\n",
       "      <th>LDA_multiclass</th>\n",
       "      <th>Ensemble_multiclass</th>\n",
       "      <th>LR_multiclass_norm</th>\n",
       "      <th>KNN_multiclass_norm</th>\n",
       "      <th>SVM_multiclass_norm</th>\n",
       "      <th>LDA_multiclass_norm</th>\n",
       "      <th>Ensemble_multiclass_norm</th>\n",
       "      <th>LR_binary</th>\n",
       "      <th>KNN_binary</th>\n",
       "      <th>SVM_binary</th>\n",
       "      <th>LDA_binary</th>\n",
       "      <th>Ensemble_binary</th>\n",
       "      <th>LR_binary_norm</th>\n",
       "      <th>KNN_binary_norm</th>\n",
       "      <th>SVM_binary_norm</th>\n",
       "      <th>LDA_binary_norm</th>\n",
       "      <th>Ensemble_binary_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.630127</td>\n",
       "      <td>0.582739</td>\n",
       "      <td>0.629936</td>\n",
       "      <td>0.610764</td>\n",
       "      <td>0.630127</td>\n",
       "      <td>0.611847</td>\n",
       "      <td>0.589936</td>\n",
       "      <td>0.630255</td>\n",
       "      <td>0.612166</td>\n",
       "      <td>0.629236</td>\n",
       "      <td>0.627389</td>\n",
       "      <td>0.631274</td>\n",
       "      <td>0.627006</td>\n",
       "      <td>0.627707</td>\n",
       "      <td>0.627516</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>0.620382</td>\n",
       "      <td>0.631019</td>\n",
       "      <td>0.631401</td>\n",
       "      <td>0.635605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.035694</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.035572</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.035694</td>\n",
       "      <td>0.034780</td>\n",
       "      <td>0.034310</td>\n",
       "      <td>0.032357</td>\n",
       "      <td>0.033376</td>\n",
       "      <td>0.033320</td>\n",
       "      <td>0.035640</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>0.034599</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.036115</td>\n",
       "      <td>0.033702</td>\n",
       "      <td>0.036523</td>\n",
       "      <td>0.033124</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>0.033502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.687898</td>\n",
       "      <td>0.732484</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.503185</td>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.554140</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.528662</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.535032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LR_multiclass  KNN_multiclass  SVM_multiclass  LDA_multiclass   \n",
       "Mean       0.630127        0.582739        0.629936        0.610764  \\\n",
       "STD        0.035694        0.032183        0.035572        0.036865   \n",
       "Max        0.707006        0.675159        0.707006        0.694268   \n",
       "Min        0.560510        0.503185        0.560510        0.535032   \n",
       "\n",
       "      Ensemble_multiclass  LR_multiclass_norm  KNN_multiclass_norm   \n",
       "Mean             0.630127            0.611847             0.589936  \\\n",
       "STD              0.035694            0.034780             0.034310   \n",
       "Max              0.707006            0.707006             0.675159   \n",
       "Min              0.560510            0.522293             0.515924   \n",
       "\n",
       "      SVM_multiclass_norm  LDA_multiclass_norm  Ensemble_multiclass_norm   \n",
       "Mean             0.630255             0.612166                  0.629236  \\\n",
       "STD              0.032357             0.033376                  0.033320   \n",
       "Max              0.707006             0.694268                  0.700637   \n",
       "Min              0.541401             0.522293                  0.541401   \n",
       "\n",
       "      LR_binary  KNN_binary  SVM_binary  LDA_binary  Ensemble_binary   \n",
       "Mean   0.627389    0.631274    0.627006    0.627707         0.627516  \\\n",
       "STD    0.035640    0.033823    0.034599    0.035628         0.036115   \n",
       "Max    0.713376    0.700637    0.700637    0.745223         0.713376   \n",
       "Min    0.522293    0.554140    0.515924    0.541401         0.515924   \n",
       "\n",
       "      LR_binary_norm  KNN_binary_norm  SVM_binary_norm  LDA_binary_norm   \n",
       "Mean        0.632038         0.620382         0.631019         0.631401  \\\n",
       "STD         0.033702         0.036523         0.033124         0.034848   \n",
       "Max         0.687898         0.732484         0.694268         0.694268   \n",
       "Min         0.535032         0.528662         0.522293         0.522293   \n",
       "\n",
       "      Ensemble_binary_norm  \n",
       "Mean              0.635605  \n",
       "STD               0.033502  \n",
       "Max               0.707006  \n",
       "Min               0.535032  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_complete = pd.concat([results, results_norm, results_binary, results_binary_norm], axis=1)\n",
    "results_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b1b92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_complete.to_csv(base_folder_filepath + '\\\\Results\\\\2023.7.17-Regions_Condensed-Results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
